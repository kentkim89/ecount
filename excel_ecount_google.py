import streamlit as st
import pandas as pd
import plotly.express as px
from streamlit_gsheets import GSheetsConnection
import google.generativeai as genai
import re

# --- Streamlit í˜ì´ì§€ ì„¤ì • ---
st.set_page_config(
    page_title="ê³ ë˜ë¯¸ ì£¼ì‹íšŒì‚¬ AI BI ëŒ€ì‹œë³´ë“œ",
    page_icon="ğŸ³",
    layout="wide"
)

# --- ì‚¬ìš©ì ì •ì˜ ì˜ì—­ ë° í•¨ìˆ˜ ---
EXCLUDED_ITEMS = [
    "ê²½ì˜ì§€ì›ë¶€ ê¸°íƒ€ì½”ë“œ", "ì¶”ê°€í• ì¸", "í”½ì—…í• ì¸",
    "KPP íŒŒë ›íŠ¸(ë¹¨ê°„ìƒ‰) (N11)", "KPP íŒŒë ›íŠ¸(íŒŒë€ìƒ‰) (N12)",
    "KPP íŒŒë ›íŠ¸ (ë¹¨ê°„ìƒ‰)", "KPP íŒŒë ›íŠ¸ (íŒŒë€ìƒ‰)",
    "[ë¶€ì¬ë£Œ]NO.320_80gì „ìš©_íŠ¸ë ˆì´_í™ˆí”ŒëŸ¬ìŠ¤ì „ìš©_KCP",
    "ë¯¸ë‹ˆë½êµ 20g ì´ì—” (ì„¸íŠ¸ìƒí’ˆ)", "ì´ˆëŒ€ë¦¬ 50g ì£¼ë¹„ (ì„¸íŠ¸ìƒí’ˆ)"
]
EXCLUDED_KEYWORDS_PATTERN = r'íƒë°°ë¹„|ìš´ì†¡ë¹„|ìˆ˜ìˆ˜ë£Œ|ì¿ í°í• ì¸|ì¶”ê°€í• ì¸|í”½ì—…í• ì¸'

def clean_product_name(name):
    if not isinstance(name, str): return name
    name = re.sub(r'\[ì™„ì œí’ˆ\]|ê³ ë˜ë¯¸|ì„¤ë˜ë‹´', '', name, flags=re.I).strip()
    spec_full = ''
    match = re.search(r'\[(.*?)\]|\((.*?)\)', name)
    if match:
        spec_full = (match.group(1) or match.group(2) or '').strip()
        name = re.sub(r'\[.*?\]|\(.*?\)', '', name).strip()
    storage = 'ëƒ‰ë™' if 'ëƒ‰ë™' in spec_full else 'ëƒ‰ì¥' if 'ëƒ‰ì¥' in spec_full else ''
    spec = re.sub(r'ëƒ‰ë™|ëƒ‰ì¥|\*|1ea|=|1kg', '', spec_full, flags=re.I).strip()
    name = re.sub(r'[_]', ' ', name).strip()
    spec = re.sub(r'[_]', ' ', spec).strip()
    name = re.sub(r'\s+', ' ', name).strip()
    spec = re.sub(r'\s+', ' ', spec).strip()
    if spec and storage: return f"{name} ({spec}) {storage}"
    elif spec: return f"{name} ({spec})"
    elif storage: return f"{name} {storage}"
    else: return name

def configure_google_ai(api_key):
    try:
        genai.configure(api_key=api_key)
        return genai.GenerativeModel('gemini-1.5-flash')
    except Exception as e:
        st.error(f"Google AI ëª¨ë¸ ì„¤ì • ì‹¤íŒ¨: {e}")
        st.stop()

def get_comparison_analysis_report(model, kpi_df, growth_cust, decline_cust, growth_prod, decline_prod, new_cust, lost_prod):
    if model is None: return "AI ëª¨ë¸ì´ ì—°ê²°ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."
    prompt = f"""
    ë‹¹ì‹ ì€ 'ê³ ë˜ë¯¸ ì£¼ì‹íšŒì‚¬'ì˜ ìˆ˜ì„ ë°ì´í„° ë¶„ì„ê°€ **'ê³ ë˜ë¯¸ AI'** ì…ë‹ˆë‹¤.
    ì•„ë˜ ì œê³µëœ ë‘ ê¸°ê°„ì˜ íŒë§¤ ì‹¤ì  ë¹„êµ ë°ì´í„°ë¥¼ ë¶„ì„í•˜ì—¬, ê²½ì˜ì§„ì„ ìœ„í•œ ì‹¤í–‰ ì¤‘ì‹¬ì˜ ë³´ê³ ì„œë¥¼ ì‘ì„±í•´ì£¼ì„¸ìš”.
    ### 1. ì£¼ìš” ì„±ê³¼ ë¹„êµ (KPI Summary)
    {kpi_df.to_markdown(index=False)}
    ### 2. ì£¼ìš” ë³€ë™ ì‚¬í•­ ë¶„ì„ (Key Changes Analysis)
    **ê°€. ê±°ë˜ì²˜ ë™í–¥:** ë§¤ì¶œ ê¸‰ìƒìŠ¹ TOP3: {', '.join(growth_cust.head(3)['ê±°ë˜ì²˜ëª…'])}, ë§¤ì¶œ ê¸‰í•˜ë½ TOP3: {', '.join(decline_cust.head(3)['ê±°ë˜ì²˜ëª…'])}, ì‹ ê·œ ê±°ë˜ì²˜ ìˆ˜: {len(new_cust)} ê³³
    **ë‚˜. ì œí’ˆ ë™í–¥:** ë§¤ì¶œ ê¸‰ìƒìŠ¹ TOP3: {', '.join(growth_prod.head(3)['ì œí’ˆëª…'])}, ë§¤ì¶œ ê¸‰í•˜ë½ TOP3: {', '.join(decline_prod.head(3)['ì œí’ˆëª…'])}, íŒë§¤ ì¤‘ë‹¨ ìƒí’ˆ ìˆ˜: {len(lost_prod)} ì¢…
    ### 3. ì¢…í•© ë¶„ì„ ë° ë‹¤ìŒ ë‹¬ ì „ëµ ì œì•ˆ
    **ê°€. ë¬´ì—‡ì´ ì´ëŸ° ë³€í™”ë¥¼ ë§Œë“¤ì—ˆëŠ”ê°€? (Root Cause Analysis):** ë§¤ì¶œì´ **ìƒìŠ¹**í–ˆë‹¤ë©´, ì–´ë–¤ ì—…ì²´ì™€ ì œí’ˆì´ ì„±ì¥ì„ ì£¼ë„í–ˆë‚˜ìš”? ê·¸ ì´ìœ ëŠ” ë¬´ì—‡ì´ë¼ê³  ì¶”ì¸¡í•˜ë‚˜ìš”? ë§¤ì¶œì´ **í•˜ë½**í–ˆë‹¤ë©´, ì–´ë–¤ ì—…ì²´ì™€ ì œí’ˆì˜ ë¶€ì§„ì´ ê°€ì¥ í° ì˜í–¥ì„ ë¯¸ì³¤ë‚˜ìš”?
    **ë‚˜. ê·¸ë˜ì„œ, ìš°ë¦¬ëŠ” ë¬´ì—‡ì„ í•´ì•¼ í•˜ëŠ”ê°€? (Actionable Recommendations):** **(ì§‘ì¤‘ ê´€ë¦¬)** ì„±ì¥ì„¸ë¥¼ ì´ì–´ê°€ê¸° ìœ„í•œ í™œë™ì€? **(ìœ„í—˜ ê´€ë¦¬)** ë¶€ì§„ í•­ëª©ì— ëŒ€í•œ ì¡°ì¹˜ëŠ”? **(ê¸°íšŒ í¬ì°©)** ì‹ ê·œ ê±°ë˜ì²˜ë¥¼ ì¶©ì„± ê³ ê°ìœ¼ë¡œ ë§Œë“¤ ì „ëµì€?
    ---
    *ë³´ê³ ì„œëŠ” ìœ„ êµ¬ì¡°ì™€ í˜•ì‹ì„ ë°˜ë“œì‹œ ì¤€ìˆ˜í•˜ì—¬, ì „ë¬¸ê°€ì˜ ì‹œê°ìœ¼ë¡œ ì‘ì„±í•´ì£¼ì„¸ìš”.*
    """
    try: return model.generate_content(prompt).text
    except Exception as e: return f"AI ë¦¬í¬íŠ¸ ìƒì„± ì¤‘ ì˜¤ë¥˜: {e}"

# --- ë°ì´í„° ì²˜ë¦¬ í•¨ìˆ˜ ---
def process_dataframe(df):
    expected_columns = ["ì¼ì-No.", "ë°°ì†¡ìƒíƒœ", "ì°½ê³ ëª…", "ê±°ë˜ì²˜ì½”ë“œ", "ê±°ë˜ì²˜ëª…", "í’ˆëª©ì½”ë“œ", "í’ˆëª©ëª…(ê·œê²©)", "ë°•ìŠ¤", "ë‚±ê°œìˆ˜ëŸ‰", "ë‹¨ê°€", "ê³µê¸‰ê°€ì•¡", "ë¶€ê°€ì„¸", "ì™¸í™”ê¸ˆì•¡", "í•©ê³„", "ì ìš”", "ì‡¼í•‘ëª°ê³ ê°ëª…", "ì‹œë¦¬ì–¼/ë¡œíŠ¸No.", "ì™¸í¬ì¥_ì—¬ë¶€", "ì „í‘œìƒíƒœ", "ì „í‘œìƒíƒœ.1", "ì¶”ê°€ë¬¸ìí˜•ì‹2", "í¬ì¥ë°•ìŠ¤", "ì¶”ê°€ìˆ«ìí˜•ì‹1", "ì‚¬ìš©ìì§€ì •ìˆ«ì1", "ì‚¬ìš©ìì§€ì •ìˆ«ì2"]
    df.columns = expected_columns[:len(df.columns)]
    numeric_cols = ["ë°•ìŠ¤", "ê³µê¸‰ê°€ì•¡", "í•©ê³„"]
    for col in numeric_cols:
        if col in df.columns: df[col] = pd.to_numeric(df[col], errors='coerce').fillna(0)
    df.dropna(subset=['ê±°ë˜ì²˜ëª…', 'í’ˆëª©ëª…(ê·œê²©)', 'ì¼ì-No.'], inplace=True)
    df['ì¼ì'] = pd.to_datetime(df['ì¼ì-No.'].astype(str).str.split('-').str[0].str.strip(), errors='coerce')
    df.dropna(subset=['ì¼ì'], inplace=True)
    df['ë…„ì›”'] = df['ì¼ì'].dt.to_period('M')
    return df

# --- ì•± ì´ˆê¸°í™” ---
st.title("ğŸ³ ê³ ë˜ë¯¸ ì£¼ì‹íšŒì‚¬ AI BI ëŒ€ì‹œë³´ë“œ (ë°ì´í„° ëˆ„ì í˜•)")

# ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
if 'db_data' not in st.session_state: st.session_state.db_data = pd.DataFrame()
if 'new_df_to_save' not in st.session_state: st.session_state.new_df_to_save = None
if 'upload_key' not in st.session_state: st.session_state.upload_key = 0

# --- API ë° DB ì—°ê²° ---
g_model, conn = None, None
try:
    g_model = configure_google_ai(st.secrets["GOOGLE_API_KEY"])
    conn = st.connection("g-sheets-connection", type=GSheetsConnection)
    st.sidebar.success("âœ… Google AI & Sheets APIê°€ ì—°ê²°ë˜ì—ˆìŠµë‹ˆë‹¤.")
except Exception as e:
    st.sidebar.error(f"ğŸš¨ API ì—°ê²° ì‹¤íŒ¨: Secrets ì„¤ì •ì„ í™•ì¸í•˜ì„¸ìš”.")
    st.stop()

# --- ë°ì´í„° ê´€ë¦¬ (ì‚¬ì´ë“œë°”) ---
with st.sidebar:
    st.header("ë°ì´í„° ê´€ë¦¬")
    
    # 1. Google Sheetsì—ì„œ í˜„ì¬ ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸°
    if conn:
        try:
            st.session_state.db_data = conn.read(worksheet="íŒë§¤í˜„í™©_ì›ë³¸", usecols=list(range(25)), ttl=10)
            status_df = process_dataframe(st.session_state.db_data.copy())
            st.info(f"**í˜„ì¬ DB í˜„í™©:** ì´ **{len(status_df)}** ê±´ ë°ì´í„°")
            st.dataframe(status_df.groupby('ë…„ì›”').size().reset_index(name='ë°ì´í„° ê±´ìˆ˜').sort_values(by='ë…„ì›”', ascending=False), height=200)
        except Exception:
            st.warning("`íŒë§¤í˜„í™©_ì›ë³¸` ì‹œíŠ¸ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ìƒˆ ë°ì´í„°ë¥¼ ì—…ë¡œë“œí•˜ì—¬ ì‹œì‘í•˜ì„¸ìš”.")
            st.session_state.db_data = pd.DataFrame()
    
    # 2. ì‹ ê·œ ë°ì´í„° ì—…ë¡œë“œ UI
    uploaded_file = st.file_uploader(
        "ğŸ“‚ **ì›”ë³„ ë°ì´í„°**ë¥¼ ì—…ë¡œë“œí•˜ì—¬ ì¶”ê°€/ìˆ˜ì •í•˜ì„¸ìš”.",
        type=["xlsx", "xls"],
        key=f"uploader_{st.session_state.upload_key}"
    )

    if uploaded_file:
        try:
            new_df = pd.read_excel(uploaded_file, sheet_name="íŒë§¤í˜„í™©", header=1)
            new_df = process_dataframe(new_df)
            file_months = new_df['ë…„ì›”'].dropna().unique()

            if len(file_months) == 1:
                file_month = file_months[0]
                st.success(f"íŒŒì¼ ê²€ì¦ ì™„ë£Œ: '{file_month}' ë°ì´í„°ê°€ í™•ì¸ë˜ì—ˆìŠµë‹ˆë‹¤.")
                st.session_state.new_df_to_save = new_df
                st.session_state.month_to_update = file_month
            else:
                st.error("ì—…ë¡œë“œ íŒŒì¼ì— ì—¬ëŸ¬ ì›”ì˜ ë°ì´í„°ê°€ ì„ì—¬ ìˆê±°ë‚˜, ë‚ ì§œ í˜•ì‹ì´ ì˜ëª»ë˜ì—ˆìŠµë‹ˆë‹¤.")
                st.session_state.new_df_to_save = None

    # 3. ë°ì´í„° ì €ì¥ ë²„íŠ¼
    if st.session_state.new_df_to_save is not None:
        if st.button(f"âœ… DBì— '{st.session_state.month_to_update}' ë°ì´í„° ì €ì¥ (ë®ì–´ì“°ê¸°)"):
            with st.spinner("Google Sheetsì— ë°ì´í„°ë¥¼ ì €ì¥í•˜ëŠ” ì¤‘ì…ë‹ˆë‹¤..."):
                existing_data = st.session_state.get('db_data', pd.DataFrame())
                if not existing_data.empty:
                    # ê¸°ì¡´ DBì—ì„œ í•´ë‹¹ ì›” ë°ì´í„° ì‚­ì œ
                    existing_data = process_dataframe(existing_data)
                    existing_data_filtered = existing_data[existing_data['ë…„ì›”'] != st.session_state.month_to_update]
                else:
                    existing_data_filtered = pd.DataFrame()
                
                # ì›ë³¸ ì»¬ëŸ¼ëª…ìœ¼ë¡œ ì¬êµ¬ì„±í•˜ì—¬ ì €ì¥
                expected_columns = ["ì¼ì-No.", "ë°°ì†¡ìƒíƒœ", "ì°½ê³ ëª…", "ê±°ë˜ì²˜ì½”ë“œ", "ê±°ë˜ì²˜ëª…", "í’ˆëª©ì½”ë“œ", "í’ˆëª©ëª…(ê·œê²©)", "ë°•ìŠ¤", "ë‚±ê°œìˆ˜ëŸ‰", "ë‹¨ê°€", "ê³µê¸‰ê°€ì•¡", "ë¶€ê°€ì„¸", "ì™¸í™”ê¸ˆì•¡", "í•©ê³„", "ì ìš”", "ì‡¼í•‘ëª°ê³ ê°ëª…", "ì‹œë¦¬ì–¼/ë¡œíŠ¸No.", "ì™¸í¬ì¥_ì—¬ë¶€", "ì „í‘œìƒíƒœ", "ì „í‘œìƒíƒœ.1", "ì¶”ê°€ë¬¸ìí˜•ì‹2", "í¬ì¥ë°•ìŠ¤", "ì¶”ê°€ìˆ«ìí˜•ì‹1", "ì‚¬ìš©ìì§€ì •ìˆ«ì1", "ì‚¬ìš©ìì§€ì •ìˆ«ì2"]
                df_to_save = pd.concat([existing_data_filtered, st.session_state.new_df_to_save], ignore_index=True)
                df_to_save_final = df_to_save[expected_columns]
                
                conn.update(worksheet="íŒë§¤í˜„í™©_ì›ë³¸", data=df_to_save_final)
                st.success(f"'{st.session_state.month_to_update}' ë°ì´í„°ë¥¼ ì„±ê³µì ìœ¼ë¡œ ì €ì¥í–ˆìŠµë‹ˆë‹¤!")
                
                # ì €ì¥ í›„ ìƒíƒœ ì´ˆê¸°í™” ë° ë¦¬ëŸ°
                st.session_state.new_df_to_save = None
                st.session_state.upload_key += 1 # íŒŒì¼ ì—…ë¡œë” í‚¤ ë³€ê²½ìœ¼ë¡œ ìœ„ì ¯ ë¦¬ì…‹
                st.rerun()

# --- ë©”ì¸ ëŒ€ì‹œë³´ë“œ ---
tab1, tab2, tab3 = st.tabs(["[1] ì¥ê¸° ì¶”ì„¸ ë¶„ì„", "[2] ì„±ê³¼ ë¹„êµ ë¶„ì„", "[3] AI ì¢…í•© ë¶„ì„"])

if 'db_data' in st.session_state and not st.session_state.db_data.empty:
    full_df = st.session_state.db_data.copy()
    analysis_df = process_and_analyze_data(full_df.copy())
    unique_months = sorted(analysis_df['ë…„ì›”'].unique(), reverse=True)

    with tab1:
        st.header("ì¥ê¸° ì¶”ì„¸ ë¶„ì„")
        st.info("ë°ì´í„°ë² ì´ìŠ¤ì— ì €ì¥ëœ ì „ì²´ ê¸°ê°„ì˜ ì„±ê³¼ ì¶”ì´ë¥¼ í™•ì¸í•©ë‹ˆë‹¤.")
        monthly_sales = analysis_df.groupby('ë…„ì›”')['í•©ê³„'].sum().reset_index()
        monthly_sales['ë…„ì›”'] = monthly_sales['ë…„ì›”'].dt.to_timestamp()
        fig = px.line(monthly_sales, x='ë…„ì›”', y='í•©ê³„', title='ì „ì²´ ê¸°ê°„ ì›”ë³„ ë§¤ì¶œ ì¶”ì´', markers=True)
        fig.update_layout(yaxis_title="ì›” ì´ë§¤ì¶œ(ì›)", xaxis_title="ë…„ì›”")
        st.plotly_chart(fig, use_container_width=True)

    if len(unique_months) >= 2:
        with tab2:
            st.header("ì„±ê³¼ ë¹„êµ ë¶„ì„")
            st.info("ë¹„êµí•˜ê³  ì‹¶ì€ ë‘ ê¸°ê°„ì„ ì„ íƒí•˜ì—¬ ì„±ê³¼ë¥¼ ë¶„ì„í•˜ì„¸ìš”.")
            c1, c2 = st.columns(2)
            curr_month_select = c1.selectbox("**ì´ë²ˆë‹¬ (ê¸°ì¤€ ì›”)**", unique_months, index=0, key='compare_current')
            prev_month_select = c2.selectbox("**ì§€ë‚œë‹¬ (ë¹„êµ ì›”)**", unique_months, index=1, key='compare_previous')

            if curr_month_select != prev_month_select:
                curr_df = analysis_df[analysis_df['ë…„ì›”'] == curr_month_select]
                prev_df = analysis_df[analysis_df['ë…„ì›”'] == prev_month_select]
                full_curr_df = full_df[full_df['ë…„ì›”'] == curr_month_select]
                full_prev_df = full_df[full_df['ë…„ì›”'] == prev_month_select]

                # (ì´í•˜ ë¹„êµ ë¶„ì„ ë¡œì§)
                kpi_data = []
                for period, df_full_period, df_analysis_period in [(prev_month_select.strftime('%Y-%m'), full_prev_df, prev_df), (curr_month_select.strftime('%Y-%m'), full_curr_df, curr_df)]:
                    kpi_data.append({'ê¸°ê°„': period, 'ì´ ê³µê¸‰ê°€ì•¡': df_full_period['ê³µê¸‰ê°€ì•¡'].sum(), 'ì´ ë§¤ì¶œ': df_full_period['í•©ê³„'].sum(), 'ì´ íŒë§¤ ë°•ìŠ¤': df_analysis_period['ë°•ìŠ¤'].sum(), 'ê±°ë˜ì²˜ ìˆ˜': df_analysis_period['ê±°ë˜ì²˜ëª…'].nunique()})
                prev_kpi, curr_kpi = kpi_data[0], kpi_data[1]
                
                st.subheader(f"{curr_month_select} vs {prev_month_select} í•µì‹¬ ì§€í‘œ ë¹„êµ")
                c1,c2,c3,c4 = st.columns(4)
                c1.metric("ì´ ê³µê¸‰ê°€ì•¡", f"{curr_kpi['ì´ ê³µê¸‰ê°€ì•¡']:,.0f} ì›", f"{curr_kpi['ì´ ê³µê¸‰ê°€ì•¡'] - prev_kpi['ì´ ê³µê¸‰ê°€ì•¡']:,.0f} ì›")
                c2.metric("ì´ ë§¤ì¶œ", f"{curr_kpi['ì´ ë§¤ì¶œ']:,.0f} ì›", f"{curr_kpi['ì´ ë§¤ì¶œ'] - prev_kpi['ì´ ë§¤ì¶œ']:,.0f} ì›")
                c3.metric("ì´ íŒë§¤ ë°•ìŠ¤", f"{curr_kpi['ì´ íŒë§¤ ë°•ìŠ¤']:,.0f} ê°œ", f"{curr_kpi['ì´ íŒë§¤ ë°•ìŠ¤'] - prev_kpi['ì´ íŒë§¤ ë°•ìŠ¤']:,.0f} ê°œ")
                c4.metric("ê±°ë˜ì²˜ ìˆ˜", f"{curr_kpi['ê±°ë˜ì²˜ ìˆ˜']} ê³³", f"{curr_kpi['ê±°ë˜ì²˜ ìˆ˜'] - prev_kpi['ê±°ë˜ì²˜ ìˆ˜']} ê³³")

                # (ì´í•˜ í…Œì´ë¸” ë° ì°¨íŠ¸ ë¡œì§)
                st.divider()
                # ... (ì´ì „ ì½”ë“œì˜ í…Œì´ë¸” ë° ì°¨íŠ¸ ìƒì„± ë¡œì§ ë³µì‚¬) ...
                prev_cust_sales = prev_df.groupby('ê±°ë˜ì²˜ëª…')['í•©ê³„'].sum()
                curr_cust_sales = curr_df.groupby('ê±°ë˜ì²˜ëª…')['í•©ê³„'].sum()
                cust_comparison = pd.merge(prev_cust_sales, curr_cust_sales, on='ê±°ë˜ì²˜ëª…', how='outer', suffixes=(f'_{prev_month_select}', f'_{curr_month_select}')).fillna(0)
                cust_comparison['ë³€ë™ì•¡'] = cust_comparison[f'í•©ê³„_{curr_month_select}'] - cust_comparison[f'í•©ê³„_{prev_month_select}']
                
                prev_prod_sales = prev_df.groupby('ì œí’ˆëª…')['í•©ê³„'].sum()
                curr_prod_sales = curr_df.groupby('ì œí’ˆëª…')['í•©ê³„'].sum()
                prod_comparison = pd.merge(prev_prod_sales, curr_prod_sales, on='ì œí’ˆëª…', how='outer', suffixes=(f'_{prev_month_select}', f'_{curr_month_select}')).fillna(0)
                prod_comparison['ë³€ë™ì•¡'] = prod_comparison[f'í•©ê³„_{curr_month_select}'] - prod_comparison[f'í•©ê³„_{prev_month_select}']
                
                top_growth_cust = cust_comparison.nlargest(10, 'ë³€ë™ì•¡').reset_index()
                top_decline_cust = cust_comparison.nsmallest(10, 'ë³€ë™ì•¡').reset_index()
                top_growth_prod = prod_comparison.nlargest(10, 'ë³€ë™ì•¡').reset_index()
                top_decline_prod = prod_comparison.nsmallest(10, 'ë³€ë™ì•¡').reset_index()
                
                c1, c2 = st.columns(2)
                with c1: st.subheader("ğŸ“ˆ ë§¤ì¶œ ê¸‰ìƒìŠ¹ ì—…ì²´ TOP 10"); st.dataframe(top_growth_cust.style.format(formatter="{:,.0f}"))
                with c2: st.subheader("ğŸ“‰ ë§¤ì¶œ ê¸‰í•˜ë½ ì—…ì²´ TOP 10"); st.dataframe(top_decline_cust.style.format(formatter="{:,.0f}"))
                c1, c2 = st.columns(2)
                with c1: st.subheader("ğŸš€ ë§¤ì¶œ ê¸‰ìƒìŠ¹ ìƒí’ˆ TOP 10"); st.dataframe(top_growth_prod.style.format(formatter="{:,.0f}"))
                with c2: st.subheader("ğŸŒ ë§¤ì¶œ ê¸‰í•˜ë½ ìƒí’ˆ TOP 10"); st.dataframe(top_decline_prod.style.format(formatter="{:,.0f}"))

        with tab3:
            st.header("AI ì¢…í•© ë¶„ì„")
            if len(unique_months) >= 2:
                st.info("`ì„±ê³¼ ë¹„êµ ë¶„ì„` íƒ­ì—ì„œ ì„ íƒëœ ë‘ ê¸°ê°„ì˜ ë¹„êµ ë°ì´í„°ë¥¼ ê¸°ë°˜ìœ¼ë¡œ AIê°€ ì¢…í•© ë¶„ì„ ë° ì „ëµì„ ì œì•ˆí•©ë‹ˆë‹¤.")
                if st.button("ğŸ“ˆ AI ë¹„êµ ë¶„ì„ ë¦¬í¬íŠ¸ ìƒì„±"):
                    if g_model:
                        with st.spinner("ê³ ë˜ë¯¸ AIê°€ ë°ì´í„°ë¥¼ ë¹„êµ ë¶„ì„í•˜ì—¬ ì „ëµì„ ìˆ˜ë¦½í•˜ê³  ìˆìŠµë‹ˆë‹¤..."):
                            kpi_df = pd.DataFrame(kpi_data)
                            prev_cust_set = set(prev_df['ê±°ë˜ì²˜ëª…'].unique()); curr_cust_set = set(curr_df['ê±°ë˜ì²˜ëª…'].unique())
                            prev_prod_set = set(prev_df['ì œí’ˆëª…'].unique()); curr_prod_set = set(curr_df['ì œí’ˆëª…'].unique())
                            new_customers = list(curr_cust_set - prev_cust_set)
                            lost_products = list(prev_prod_set - curr_prod_set)
                            report = get_comparison_analysis_report(g_model, pd.DataFrame(kpi_data), top_growth_cust, top_decline_cust, top_growth_prod, top_decline_prod, new_customers, lost_products)
                            st.markdown(report)
                    else: st.warning("AI ëª¨ë¸ì´ ì—°ê²°ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
            else:
                st.warning("AI ë¶„ì„ì„ ìœ„í•´ì„œëŠ” ìµœì†Œ 2ê°œì›”ì¹˜ì˜ ë°ì´í„°ê°€ í•„ìš”í•©ë‹ˆë‹¤.")
    else:
        st.warning("ë°ì´í„°ë² ì´ìŠ¤ì— ìµœì†Œ 2ê°œì›”ì¹˜ì˜ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. '[1] ë°ì´í„° ê´€ë¦¬' íƒ­ì—ì„œ ë°ì´í„°ë¥¼ ì¶”ê°€í•´ì£¼ì„¸ìš”.")

else:
    st.info("ğŸ‘ˆ ì‚¬ì´ë“œë°”ì—ì„œ íŒë§¤í˜„í™© ì—‘ì…€ íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì—¬ ë¶„ì„ì„ ì‹œì‘í•˜ì„¸ìš”.")
