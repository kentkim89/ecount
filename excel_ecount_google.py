import streamlit as st
import pandas as pd
import plotly.express as px
import google.generativeai as genai
import re

# --- Streamlit í˜ì´ì§€ ì„¤ì • ---
st.set_page_config(
    page_title="ê³ ë˜ë¯¸ ì£¼ì‹íšŒì‚¬ AI íŒë§¤ ë¶„ì„ ëŒ€ì‹œë³´ë“œ",
    page_icon="ğŸ³",
    layout="wide"
)

# --- ì‚¬ìš©ì ì •ì˜ ì˜ì—­ ë° í•¨ìˆ˜ ---
EXCLUDED_ITEMS = [
    "ê²½ì˜ì§€ì›ë¶€ ê¸°íƒ€ì½”ë“œ", "ì¶”ê°€í• ì¸", "í”½ì—…í• ì¸",
    "KPP íŒŒë ›íŠ¸(ë¹¨ê°„ìƒ‰) (N11)", "KPP íŒŒë ›íŠ¸(íŒŒë€ìƒ‰) (N12)",
    "KPP íŒŒë ›íŠ¸ (ë¹¨ê°„ìƒ‰)", "KPP íŒŒë ›íŠ¸ (íŒŒë€ìƒ‰)",
    "[ë¶€ì¬ë£Œ]NO.320_80gì „ìš©_íŠ¸ë ˆì´_í™ˆí”ŒëŸ¬ìŠ¤ì „ìš©_KCP",
    "ë¯¸ë‹ˆë½êµ 20g ì´ì—” (ì„¸íŠ¸ìƒí’ˆ)", "ì´ˆëŒ€ë¦¬ 50g ì£¼ë¹„ (ì„¸íŠ¸ìƒí’ˆ)"
]
EXCLUDED_KEYWORDS_PATTERN = r'íƒë°°ë¹„|ìš´ì†¡ë¹„|ìˆ˜ìˆ˜ë£Œ|ì¿ í°í• ì¸|ì¶”ê°€í• ì¸|í”½ì—…í• ì¸'

@st.cache_data
def clean_product_name(name):
    if not isinstance(name, str): return name
    name = re.sub(r'\[ì™„ì œí’ˆ\]|ê³ ë˜ë¯¸|ì„¤ë˜ë‹´', '', name, flags=re.I).strip()
    spec_full = ''
    match = re.search(r'\[(.*?)\]|\((.*?)\)', name)
    if match:
        spec_full = (match.group(1) or match.group(2) or '').strip()
        name = re.sub(r'\[.*?\]|\(.*?\)', '', name).strip()
    storage = 'ëƒ‰ë™' if 'ëƒ‰ë™' in spec_full else 'ëƒ‰ì¥' if 'ëƒ‰ì¥' in spec_full else ''
    spec = re.sub(r'ëƒ‰ë™|ëƒ‰ì¥|\*|1ea|=|1kg', '', spec_full, flags=re.I).strip()
    name = re.sub(r'[_]', ' ', name).strip()
    spec = re.sub(r'[_]', ' ', spec).strip()
    name = re.sub(r'\s+', ' ', name).strip()
    spec = re.sub(r'\s+', ' ', spec).strip()
    if spec and storage: return f"{name} ({spec}) {storage}"
    elif spec: return f"{name} ({spec})"
    elif storage: return f"{name} {storage}"
    else: return name

def configure_google_ai(api_key):
    try:
        genai.configure(api_key=api_key)
        return genai.GenerativeModel('gemini-1.5-flash')
    except Exception as e:
        st.error(f"Google AI ëª¨ë¸ ì„¤ì • ì‹¤íŒ¨: {e}")
        st.stop()

@st.cache_data
def process_uploaded_file(uploaded_file):
    try:
        df = pd.read_excel(uploaded_file, sheet_name="íŒë§¤í˜„í™©", header=1)
        expected_columns = ["ì¼ì-No.", "ë°°ì†¡ìƒíƒœ", "ì°½ê³ ëª…", "ê±°ë˜ì²˜ì½”ë“œ", "ê±°ë˜ì²˜ëª…", "í’ˆëª©ì½”ë“œ", "í’ˆëª©ëª…(ê·œê²©)", "ë°•ìŠ¤", "ë‚±ê°œìˆ˜ëŸ‰", "ë‹¨ê°€", "ê³µê¸‰ê°€ì•¡", "ë¶€ê°€ì„¸", "ì™¸í™”ê¸ˆì•¡", "í•©ê³„", "ì ìš”", "ì‡¼í•‘ëª°ê³ ê°ëª…", "ì‹œë¦¬ì–¼/ë¡œíŠ¸No.", "ì™¸í¬ì¥_ì—¬ë¶€", "ì „í‘œìƒíƒœ", "ì „í‘œìƒíƒœ.1", "ì¶”ê°€ë¬¸ìí˜•ì‹2", "í¬ì¥ë°•ìŠ¤", "ì¶”ê°€ìˆ«ìí˜•ì‹1", "ì‚¬ìš©ìì§€ì •ìˆ«ì1", "ì‚¬ìš©ìì§€ì •ìˆ«ì2"]
        df.columns = expected_columns[:len(df.columns)]
        numeric_cols = ["ë°•ìŠ¤", "ê³µê¸‰ê°€ì•¡", "í•©ê³„"]
        for col in numeric_cols:
            if col in df.columns: df[col] = pd.to_numeric(df[col], errors='coerce').fillna(0)
        
        df.dropna(subset=['ê±°ë˜ì²˜ëª…', 'í’ˆëª©ëª…(ê·œê²©)', 'ì¼ì-No.'], inplace=True)
        df['ì¼ì'] = pd.to_datetime(df['ì¼ì-No.'].astype(str).str.split('-').str[0].str.strip(), errors='coerce')
        df.dropna(subset=['ì¼ì'], inplace=True)
        df['ë…„ì›”'] = df['ì¼ì'].dt.to_period('M')
        
        # ì „ì²´ ë°ì´í„°(df)ì™€ ë¶„ì„ìš© ë°ì´í„°(analysis_df) ë¶„ë¦¬
        mask_static = df['í’ˆëª©ëª…(ê·œê²©)'].str.strip().isin(EXCLUDED_ITEMS)
        mask_pattern = df['í’ˆëª©ëª…(ê·œê²©)'].str.contains(EXCLUDED_KEYWORDS_PATTERN, na=False)
        combined_mask = mask_static | mask_pattern
        
        analysis_df = df[~combined_mask].copy()
        analysis_df['ì œí’ˆëª…'] = analysis_df['í’ˆëª©ëª…(ê·œê²©)'].apply(clean_product_name)
        analysis_df = analysis_df[analysis_df['ì œí’ˆëª…'].str.strip() != '']
        return df, analysis_df
    except Exception as e:
        st.error(f"íŒŒì¼ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {e}")
        return None, None

def get_comparison_analysis_report(_model, kpi_df, growth_cust, decline_cust, growth_prod, decline_prod, new_cust, lost_prod):
    prompt = f"""
    ë‹¹ì‹ ì€ 'ê³ ë˜ë¯¸ ì£¼ì‹íšŒì‚¬'ì˜ ìˆ˜ì„ ë°ì´í„° ë¶„ì„ê°€ **'ê³ ë˜ë¯¸ AI'** ì…ë‹ˆë‹¤.
    ì•„ë˜ ì œê³µëœ ë‘ ê¸°ê°„ì˜ íŒë§¤ ì‹¤ì  ë¹„êµ ë°ì´í„°ë¥¼ ë¶„ì„í•˜ì—¬, ê²½ì˜ì§„ì„ ìœ„í•œ ì‹¤í–‰ ì¤‘ì‹¬ì˜ ë³´ê³ ì„œë¥¼ ì‘ì„±í•´ì£¼ì„¸ìš”.
    ### 1. ì£¼ìš” ì„±ê³¼ ë¹„êµ (KPI Summary)
    {kpi_df.to_markdown(index=False)}
    ### 2. ì£¼ìš” ë³€ë™ ì‚¬í•­ ë¶„ì„ (Key Changes Analysis)
    **ê°€. ê±°ë˜ì²˜ ë™í–¥:**
    - **ë§¤ì¶œ ê¸‰ìƒìŠ¹ TOP3:** {', '.join(growth_cust.head(3)['ê±°ë˜ì²˜ëª…'])}
    - **ë§¤ì¶œ ê¸‰í•˜ë½ TOP3:** {', '.join(decline_cust.head(3)['ê±°ë˜ì²˜ëª…'])}
    - **ì‹ ê·œ ê±°ë˜ì²˜ ìˆ˜:** {len(new_cust)} ê³³
    **ë‚˜. ì œí’ˆ ë™í–¥:**
    - **ë§¤ì¶œ ê¸‰ìƒìŠ¹ TOP3:** {', '.join(growth_prod.head(3)['ì œí’ˆëª…'])}
    - **ë§¤ì¶œ ê¸‰í•˜ë½ TOP3:** {', '.join(decline_prod.head(3)['ì œí’ˆëª…'])}
    - **íŒë§¤ ì¤‘ë‹¨(ì´íƒˆ) ìƒí’ˆ ìˆ˜:** {len(lost_prod)} ì¢…
    ### 3. ì¢…í•© ë¶„ì„ ë° ë‹¤ìŒ ë‹¬ ì „ëµ ì œì•ˆ
    **ê°€. ë¬´ì—‡ì´ ì´ëŸ° ë³€í™”ë¥¼ ë§Œë“¤ì—ˆëŠ”ê°€? (Root Cause Analysis):**
    - ë§¤ì¶œì´ **ìƒìŠ¹**í–ˆë‹¤ë©´, ì–´ë–¤ ì—…ì²´ì™€ ì œí’ˆì´ ì„±ì¥ì„ ì£¼ë„í–ˆë‚˜ìš”? ê·¸ ì´ìœ ëŠ” ë¬´ì—‡ì´ë¼ê³  ì¶”ì¸¡í•˜ë‚˜ìš”?
    - ë§¤ì¶œì´ **í•˜ë½**í–ˆë‹¤ë©´, ì–´ë–¤ ì—…ì²´ì™€ ì œí’ˆì˜ ë¶€ì§„ì´ ê°€ì¥ í° ì˜í–¥ì„ ë¯¸ì³¤ë‚˜ìš”?
    - ì‹ ê·œ ê±°ë˜ì²˜ì˜ ë°œìƒê³¼ ê¸°ì¡´ ê±°ë˜ì²˜ì˜ ë§¤ì¶œ í•˜ë½ ì‚¬ì´ì— ì—°ê´€ì„±ì´ ìˆë‚˜ìš”?
    **ë‚˜. ê·¸ë˜ì„œ, ìš°ë¦¬ëŠ” ë¬´ì—‡ì„ í•´ì•¼ í•˜ëŠ”ê°€? (Actionable Recommendations):**
    - **(ì§‘ì¤‘ ê´€ë¦¬)** ë§¤ì¶œì´ ê¸‰ìƒìŠ¹í•œ ê±°ë˜ì²˜ì™€ ì œí’ˆì˜ ì„±ì¥ì„¸ë¥¼ ì´ì–´ê°€ê¸° ìœ„í•´ ë‹¤ìŒ ë‹¬ì— ì–´ë–¤ í™œë™ì„ í•´ì•¼ í• ê¹Œìš”?
    - **(ìœ„í—˜ ê´€ë¦¬)** ë§¤ì¶œì´ ê¸‰í•˜ë½í•œ ê±°ë˜ì²˜ì™€ ì œí’ˆì— ëŒ€í•´ì„œëŠ” ì–´ë–¤ ì¡°ì¹˜ë¥¼ ì·¨í•´ì•¼ í• ê¹Œìš”?
    - **(ê¸°íšŒ í¬ì°©)** ì‹ ê·œ ê±°ë˜ì²˜ë¥¼ ì¶©ì„± ê³ ê°ìœ¼ë¡œ ë§Œë“¤ê¸° ìœ„í•œ ì „ëµê³¼, ì´íƒˆ ìƒí’ˆì˜ ì¬íŒë§¤ ë˜ëŠ” ë‹¨ì¢… ì—¬ë¶€ ê²°ì •ì— ëŒ€í•œ ë‹¹ì‹ ì˜ ì˜ê²¬ì„ ì œì‹œí•´ì£¼ì„¸ìš”.
    ---
    *ë³´ê³ ì„œëŠ” ìœ„ êµ¬ì¡°ì™€ í˜•ì‹ì„ ë°˜ë“œì‹œ ì¤€ìˆ˜í•˜ì—¬, ì „ë¬¸ê°€ì˜ ì‹œê°ìœ¼ë¡œ ì‘ì„±í•´ì£¼ì„¸ìš”.*
    """
    try:
        response = _model.generate_content(prompt)
        return response.text
    except Exception as e:
        return f"AI ë¦¬í¬íŠ¸ ìƒì„± ì¤‘ ì˜¤ë¥˜: {e}"

# --- ì•± ì´ˆê¸°í™” ---
st.title("ğŸ³ ê³ ë˜ë¯¸ ì£¼ì‹íšŒì‚¬ AI íŒë§¤ ë¶„ì„ ëŒ€ì‹œë³´ë“œ")
g_model = None
try:
    g_model = configure_google_ai(st.secrets["GOOGLE_API_KEY"])
    st.sidebar.success("âœ… AI ëª¨ë¸ì´ ì„±ê³µì ìœ¼ë¡œ ì—°ê²°ë˜ì—ˆìŠµë‹ˆë‹¤.")
except KeyError:
    st.sidebar.error("âš ï¸ GOOGLE_API_KEYë¥¼ Secretsì— ì¶”ê°€í•´ì£¼ì„¸ìš”.")
except Exception as e:
    st.sidebar.error(f"ğŸš¨ AI ëª¨ë¸ ì—°ê²° ì‹¤íŒ¨: {e}")

# --- ë°ì´í„° ì—…ë¡œë“œ ---
with st.sidebar:
    st.header("ë°ì´í„° ì—…ë¡œë“œ")
    uploaded_file = st.file_uploader("ğŸ“‚ íŒë§¤í˜„í™© ì—‘ì…€ íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì„¸ìš”.", type=["xlsx", "xls"])

# --- ë©”ì¸ ëŒ€ì‹œë³´ë“œ ---
if uploaded_file:
    with st.spinner("ëŒ€ìš©ëŸ‰ íŒŒì¼ì„ ì²˜ë¦¬í•˜ëŠ” ì¤‘ì…ë‹ˆë‹¤. ì ì‹œë§Œ ê¸°ë‹¤ë ¤ì£¼ì„¸ìš”..."):
        full_df, analysis_df = process_uploaded_file(uploaded_file)
    
    if analysis_df is not None:
        st.success("íŒŒì¼ ì²˜ë¦¬ ì™„ë£Œ! ë¶„ì„ì„ ì‹œì‘í•©ë‹ˆë‹¤.")
        unique_months = sorted(analysis_df['ë…„ì›”'].unique(), reverse=True)
        
        if len(unique_months) >= 2:
            tab1, tab2, tab3 = st.tabs(["[1] ì¥ê¸° ì¶”ì„¸ ë¶„ì„", "[2] ì„±ê³¼ ë¹„êµ ë¶„ì„", "[3] AI ì¢…í•© ë¶„ì„"])

            with tab1:
                st.header("ì¥ê¸° ì¶”ì„¸ ë¶„ì„")
                st.info("ì—…ë¡œë“œëœ íŒŒì¼ì˜ ì „ì²´ ê¸°ê°„ì— ëŒ€í•œ ì„±ê³¼ ì¶”ì´ë¥¼ í™•ì¸í•©ë‹ˆë‹¤.")
                monthly_sales = analysis_df.groupby('ë…„ì›”')['í•©ê³„'].sum().reset_index()
                monthly_sales['ë…„ì›”'] = monthly_sales['ë…„ì›”'].dt.to_timestamp()
                fig = px.line(monthly_sales, x='ë…„ì›”', y='í•©ê³„', title='ì „ì²´ ê¸°ê°„ ì›”ë³„ ë§¤ì¶œ ì¶”ì´', markers=True, template="plotly_white")
                fig.update_layout(yaxis_title="ì›” ì´ë§¤ì¶œ(ì›)", xaxis_title="ë…„ì›”")
                st.plotly_chart(fig, use_container_width=True)

            with tab2:
                st.header("ì„±ê³¼ ë¹„êµ ë¶„ì„")
                st.info("ë¹„êµí•˜ê³  ì‹¶ì€ ë‘ ê¸°ê°„ì„ ì„ íƒí•˜ì—¬ ì„±ê³¼ë¥¼ ë¶„ì„í•˜ì„¸ìš”.")
                c1, c2 = st.columns(2)
                curr_month_select = c1.selectbox("**ì´ë²ˆë‹¬ (ê¸°ì¤€ ì›”)**", unique_months, index=0)
                prev_month_select = c2.selectbox("**ì§€ë‚œë‹¬ (ë¹„êµ ì›”)**", unique_months, index=1)

                if curr_month_select != prev_month_select:
                    curr_df = analysis_df[analysis_df['ë…„ì›”'] == curr_month_select]
                    prev_df = analysis_df[analysis_df['ë…„ì›”'] == prev_month_select]
                    full_curr_df = full_df[full_df['ë…„ì›”'] == curr_month_select]
                    full_prev_df = full_df[full_df['ë…„ì›”'] == prev_month_select]

                    # KPI ê³„ì‚°
                    kpi_data = []
                    for period, df_full_period, df_analysis_period in [(prev_month_select.strftime('%Y-%m'), full_prev_df, prev_df), (curr_month_select.strftime('%Y-%m'), full_curr_df, curr_df)]:
                        kpi_data.append({'ê¸°ê°„': period, 'ì´ ê³µê¸‰ê°€ì•¡': df_full_period['ê³µê¸‰ê°€ì•¡'].sum(), 'ì´ ë§¤ì¶œ': df_full_period['í•©ê³„'].sum(), 'ì´ íŒë§¤ ë°•ìŠ¤': df_analysis_period['ë°•ìŠ¤'].sum(), 'ê±°ë˜ì²˜ ìˆ˜': df_analysis_period['ê±°ë˜ì²˜ëª…'].nunique()})
                    prev_kpi, curr_kpi = kpi_data[0], kpi_data[1]
                    
                    st.subheader(f"{curr_month_select} vs {prev_month_select} í•µì‹¬ ì§€í‘œ ë¹„êµ")
                    c1,c2,c3,c4 = st.columns(4)
                    c1.metric("ì´ ê³µê¸‰ê°€ì•¡", f"{curr_kpi['ì´ ê³µê¸‰ê°€ì•¡']:,.0f} ì›", f"{curr_kpi['ì´ ê³µê¸‰ê°€ì•¡'] - prev_kpi['ì´ ê³µê¸‰ê°€ì•¡']:,.0f} ì›")
                    c2.metric("ì´ ë§¤ì¶œ", f"{curr_kpi['ì´ ë§¤ì¶œ']:,.0f} ì›", f"{curr_kpi['ì´ ë§¤ì¶œ'] - prev_kpi['ì´ ë§¤ì¶œ']:,.0f} ì›")
                    c3.metric("ì´ íŒë§¤ ë°•ìŠ¤", f"{curr_kpi['ì´ íŒë§¤ ë°•ìŠ¤']:,.0f} ê°œ", f"{curr_kpi['ì´ íŒë§¤ ë°•ìŠ¤'] - prev_kpi['ì´ íŒë§¤ ë°•ìŠ¤']:,.0f} ê°œ")
                    c4.metric("ê±°ë˜ì²˜ ìˆ˜", f"{curr_kpi['ê±°ë˜ì²˜ ìˆ˜']} ê³³", f"{curr_kpi['ê±°ë˜ì²˜ ìˆ˜'] - prev_kpi['ê±°ë˜ì²˜ ìˆ˜']} ê³³")

                    # ë¹„êµ í…Œì´ë¸” ìƒì„±
                    st.divider()
                    prev_cust_sales = prev_df.groupby('ê±°ë˜ì²˜ëª…')['í•©ê³„'].sum()
                    curr_cust_sales = curr_df.groupby('ê±°ë˜ì²˜ëª…')['í•©ê³„'].sum()
                    cust_comparison = pd.merge(prev_cust_sales, curr_cust_sales, on='ê±°ë˜ì²˜ëª…', how='outer', suffixes=(f'_{prev_month_select}', f'_{curr_month_select}')).fillna(0)
                    cust_comparison['ë³€ë™ì•¡'] = cust_comparison[f'í•©ê³„_{curr_month_select}'] - cust_comparison[f'í•©ê³„_{prev_month_select}']
                    
                    prev_prod_sales = prev_df.groupby('ì œí’ˆëª…')['í•©ê³„'].sum()
                    curr_prod_sales = curr_df.groupby('ì œí’ˆëª…')['í•©ê³„'].sum()
                    prod_comparison = pd.merge(prev_prod_sales, curr_prod_sales, on='ì œí’ˆëª…', how='outer', suffixes=(f'_{prev_month_select}', f'_{curr_month_select}')).fillna(0)
                    prod_comparison['ë³€ë™ì•¡'] = prod_comparison[f'í•©ê³„_{curr_month_select}'] - prod_comparison[f'í•©ê³„_{prev_month_select}']
                    
                    top_growth_cust = cust_comparison.nlargest(10, 'ë³€ë™ì•¡').reset_index()
                    top_decline_cust = cust_comparison.nsmallest(10, 'ë³€ë™ì•¡').reset_index()
                    top_growth_prod = prod_comparison.nlargest(10, 'ë³€ë™ì•¡').reset_index()
                    top_decline_prod = prod_comparison.nsmallest(10, 'ë³€ë™ì•¡').reset_index()
                    
                    c1, c2 = st.columns(2)
                    with c1: st.subheader("ğŸ“ˆ ë§¤ì¶œ ê¸‰ìƒìŠ¹ ì—…ì²´ TOP 10"); st.dataframe(top_growth_cust.style.format(formatter="{:,.0f}"))
                    with c2: st.subheader("ğŸ“‰ ë§¤ì¶œ ê¸‰í•˜ë½ ì—…ì²´ TOP 10"); st.dataframe(top_decline_cust.style.format(formatter="{:,.0f}"))
                    c1, c2 = st.columns(2)
                    with c1: st.subheader("ğŸš€ ë§¤ì¶œ ê¸‰ìƒìŠ¹ ìƒí’ˆ TOP 10"); st.dataframe(top_growth_prod.style.format(formatter="{:,.0f}"))
                    with c2: st.subheader("ğŸŒ ë§¤ì¶œ ê¸‰í•˜ë½ ìƒí’ˆ TOP 10"); st.dataframe(top_decline_prod.style.format(formatter="{:,.0f}"))
                else:
                    st.warning("ë¹„êµí•  ë‘ ê¸°ê°„ì„ ë‹¤ë¥´ê²Œ ì„ íƒí•´ì£¼ì„¸ìš”.")

            with tab3:
                st.header("AI ì¢…í•© ë¶„ì„")
                if 'curr_month_select' in locals() and 'prev_month_select' in locals() and curr_month_select != prev_month_select:
                    st.info(f"`{curr_month_select}`ì™€ `{prev_month_select}`ì˜ ë¹„êµ ë°ì´í„°ë¥¼ ê¸°ë°˜ìœ¼ë¡œ AIê°€ ì¢…í•© ë¶„ì„ ë° ì „ëµì„ ì œì•ˆí•©ë‹ˆë‹¤.")
                    if st.button("ğŸ“ˆ AI ë¹„êµ ë¶„ì„ ë¦¬í¬íŠ¸ ìƒì„±"):
                        if g_model:
                            with st.spinner("ê³ ë˜ë¯¸ AIê°€ ë°ì´í„°ë¥¼ ë¹„êµ ë¶„ì„í•˜ì—¬ ì „ëµì„ ìˆ˜ë¦½í•˜ê³  ìˆìŠµë‹ˆë‹¤..."):
                                prev_cust_set = set(prev_df['ê±°ë˜ì²˜ëª…'].unique()); curr_cust_set = set(curr_df['ê±°ë˜ì²˜ëª…'].unique())
                                prev_prod_set = set(prev_df['ì œí’ˆëª…'].unique()); curr_prod_set = set(curr_df['ì œí’ˆëª…'].unique())
                                new_customers = list(curr_cust_set - prev_cust_set)
                                lost_products = list(prev_prod_set - curr_prod_set)
                                report = get_comparison_analysis_report(g_model, pd.DataFrame(kpi_data), top_growth_cust, top_decline_cust, top_growth_prod, top_decline_prod, new_customers, lost_products)
                                st.markdown(report)
                        else:
                            st.warning("AI ëª¨ë¸ì´ ì—°ê²°ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
                else:
                    st.warning("ë¨¼ì € `ì„±ê³¼ ë¹„êµ ë¶„ì„` íƒ­ì—ì„œ ë¹„êµí•  ë‘ ê¸°ê°„ì„ ì„ íƒí•´ì£¼ì„¸ìš”.")
        else:
            st.warning("íŒŒì¼ì— ìµœì†Œ 2ê°œì›” ì´ìƒì˜ ë°ì´í„°ê°€ ìˆì–´ì•¼ ë¹„êµ ë¶„ì„ì´ ê°€ëŠ¥í•©ë‹ˆë‹¤.")
else:
    st.info("ğŸ‘ˆ ì‚¬ì´ë“œë°”ì—ì„œ íŒë§¤í˜„í™© ì—‘ì…€ íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì—¬ ë¶„ì„ì„ ì‹œì‘í•˜ì„¸ìš”.")
