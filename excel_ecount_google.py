import streamlit as st
import pandas as pd
import plotly.express as px
import plotly.graph_objects as go
from io import BytesIO
import google.generativeai as genai
import re
import requests # ë„¤ì´ë²„ API í˜¸ì¶œì„ ìœ„í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬
import json
from datetime import datetime, timedelta

# --- Streamlit í˜ì´ì§€ ì„¤ì • ---
st.set_page_config(
    page_title="ê³ ë˜ë¯¸ ì£¼ì‹íšŒì‚¬ AI ë¹„ì¦ˆë‹ˆìŠ¤ ì¸í…”ë¦¬ì „ìŠ¤",
    page_icon="ğŸ³",
    layout="wide"
)

# --- ì‚¬ìš©ì ì •ì˜ ì˜ì—­ ---
EXCLUDED_ITEMS = [
    "ê²½ì˜ì§€ì›ë¶€ ê¸°íƒ€ì½”ë“œ", "ì¶”ê°€í• ì¸", "í”½ì—…í• ì¸",
    "KPP íŒŒë ›íŠ¸(ë¹¨ê°„ìƒ‰) (N11)", "KPP íŒŒë ›íŠ¸(íŒŒë€ìƒ‰) (N12)",
    "KPP íŒŒë ›íŠ¸ (ë¹¨ê°„ìƒ‰)", "KPP íŒŒë ›íŠ¸ (íŒŒë€ìƒ‰)",
    "[ë¶€ì¬ë£Œ]NO.320_80gì „ìš©_íŠ¸ë ˆì´_í™ˆí”ŒëŸ¬ìŠ¤ì „ìš©_KCP",
    "ë¯¸ë‹ˆë½êµ 20g ì´ì—” (ì„¸íŠ¸ìƒí’ˆ)", "ì´ˆëŒ€ë¦¬ 50g ì£¼ë¹„ (ì„¸íŠ¸ìƒí’ˆ)"
]
EXCLUDED_KEYWORDS_PATTERN = r'íƒë°°ë¹„|ìš´ì†¡ë¹„|ìˆ˜ìˆ˜ë£Œ|ì¿ í°í• ì¸|ì¶”ê°€í• ì¸|í”½ì—…í• ì¸'

# --- ë°ì´í„° í´ë¦¬ë‹ ë° AI í•¨ìˆ˜ (ì´ì „ê³¼ ë™ì¼) ---
def clean_product_name(name):
    if not isinstance(name, str): return name
    brands_and_prefixes = r'\[ì™„ì œí’ˆ\]|ê³ ë˜ë¯¸|ì„¤ë˜ë‹´'
    name = re.sub(brands_and_prefixes, '', name, flags=re.I).strip()
    spec_full = ''
    match = re.search(r'\[(.*?)\]|\((.*?)\)', name)
    if match:
        spec_full = (match.group(1) or match.group(2) or '').strip()
        name = re.sub(r'\[.*?\]|\(.*?\)', '', name).strip()
    storage = 'ëƒ‰ë™' if 'ëƒ‰ë™' in spec_full else 'ëƒ‰ì¥' if 'ëƒ‰ì¥' in spec_full else ''
    spec = re.sub(r'ëƒ‰ë™|ëƒ‰ì¥|\*|1ea|=|1kg', '', spec_full, flags=re.I).strip()
    name = re.sub(r'[_]', ' ', name).strip()
    spec = re.sub(r'[_]', ' ', spec).strip()
    name = re.sub(r'\s+', ' ', name).strip()
    spec = re.sub(r'\s+', ' ', spec).strip()
    if spec and storage: return f"{name} ({spec}) {storage}"
    elif spec: return f"{name} ({spec})"
    elif storage: return f"{name} {storage}"
    else: return name

def configure_google_ai(api_key):
    try:
        genai.configure(api_key=api_key)
        model = genai.GenerativeModel('gemini-1.5-flash')
        return model
    except Exception as e:
        st.error(f"Google AI ëª¨ë¸ ì„¤ì •ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤: {e}")
        st.stop()

# --- ë„¤ì´ë²„ API í˜¸ì¶œ í•¨ìˆ˜ ---
def call_naver_datalab(api_id, api_secret, keyword):
    end_date = datetime.today().strftime('%Y-%m-%d')
    start_date = (datetime.today() - timedelta(days=365)).strftime('%Y-%m-%d')
    body = {
        "startDate": start_date,
        "endDate": end_date,
        "timeUnit": "month",
        "keywordGroups": [{"groupName": keyword, "keywords": [keyword]}]
    }
    url = "https://openapi.naver.com/v1/datalab/search"
    headers = {"X-Naver-Client-Id": api_id, "X-Naver-Client-Secret": api_secret, "Content-Type": "application/json"}
    try:
        response = requests.post(url, headers=headers, data=json.dumps(body))
        response.raise_for_status()
        return response.json()
    except requests.exceptions.RequestException as e:
        st.error(f"ë„¤ì´ë²„ ë°ì´í„°ë© API í˜¸ì¶œ ì˜¤ë¥˜: {e}")
        return None

def call_naver_shopping(api_id, api_secret, keyword):
    url = f"https://openapi.naver.com/v1/search/shop.json?query={keyword}&display=10"
    headers = {"X-Naver-Client-Id": api_id, "X-Naver-Client-Secret": api_secret}
    try:
        response = requests.get(url, headers=headers)
        response.raise_for_status()
        return response.json()
    except requests.exceptions.RequestException as e:
        st.error(f"ë„¤ì´ë²„ ì‡¼í•‘ API í˜¸ì¶œ ì˜¤ë¥˜: {e}")
        return None

# --- AI ì „ëµ ë¶„ì„ í•¨ìˆ˜ ---
def get_market_analysis_report(model, keyword, datalab_result, shopping_result):
    if model is None: return "AI ëª¨ë¸ì´ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."

    prompt = f"""
    ë‹¹ì‹ ì€ ëŒ€í•œë¯¼êµ­ ìµœê³ ì˜ ë°ì´í„° ê¸°ë°˜ ë§ˆì¼€í„° **'ê³ ë˜ë¯¸ AI'** ì…ë‹ˆë‹¤.
    ì•„ë˜ ì œê³µëœ **ë„¤ì´ë²„ ì‹¤ì‹œê°„ ì‹œì¥ ë°ì´í„°**ë¥¼ ë¶„ì„í•˜ì—¬, '{keyword}' í‚¤ì›Œë“œì— ëŒ€í•œ ë§ˆì¼€íŒ… ì „ëµ ë³´ê³ ì„œë¥¼ ì‘ì„±í•´ì£¼ì„¸ìš”.

    ### 1. ì‹œì¥ ë°ì´í„° (Source: Naver API)

    **ê°€. ê²€ìƒ‰ëŸ‰ íŠ¸ë Œë“œ (ìµœê·¼ 1ë…„, ì›”ë³„)**
    - ë°ì´í„°: {json.dumps(datalab_result['results'][0]['data'], ensure_ascii=False)}
    - ë¶„ì„: ë°ì´í„°ì—ì„œ ë‚˜íƒ€ë‚˜ëŠ” ê³„ì ˆì  ì„±ìˆ˜ê¸°, ë¹„ìˆ˜ê¸° ë˜ëŠ” íŠ¹ë³„í•œ ê¸‰ë“±/ê¸‰ë½ ì§€ì ì„ ì§šì–´ì£¼ì„¸ìš”.

    **ë‚˜. ì‡¼í•‘ ê²€ìƒ‰ ê²°ê³¼ (ìƒìœ„ 10ê°œ)**
    - ê²½ìŸ ì œí’ˆ ë¦¬ìŠ¤íŠ¸:
    ```
    {pd.DataFrame(shopping_result['items'])[['title', 'lprice', 'brand']].to_string()}
    ```
    - ë¶„ì„: ê²½ìŸ ì œí’ˆë“¤ì˜ ë„¤ì´ë° íŠ¹ì§•, í‰ê·  ê°€ê²©ëŒ€, ì£¼ìš” ë¸Œëœë“œë¥¼ ê°„ëµíˆ ìš”ì•½í•´ì£¼ì„¸ìš”.

    ### 2. ë§ˆì¼€íŒ… ì „ëµ ì œì•ˆ

    ìœ„ ì‹œì¥ ë°ì´í„°ë¥¼ ë°”íƒ•ìœ¼ë¡œ, ì•„ë˜ í•­ëª©ì— ëŒ€í•´ êµ¬ì²´ì ì´ê³  ì‹¤í–‰ ê°€ëŠ¥í•œ ì „ëµì„ ì œì‹œí•´ì£¼ì„¸ìš”.

    **ê°€. íƒ€ê²Ÿ ê³ ê° í”„ë¡œí•„ (Target Persona)**
    - ì–´ë–¤ ê³ ê°ì´ '{keyword}'ë¥¼ ê²€ìƒ‰í• ì§€, ê·¸ë“¤ì˜ ë‹ˆì¦ˆ(Needs)ëŠ” ë¬´ì—‡ì¼ì§€ êµ¬ì²´ì ìœ¼ë¡œ ë¬˜ì‚¬í•´ì£¼ì„¸ìš”.

    **ë‚˜. í•µì‹¬ ë§ˆì¼€íŒ… ë©”ì‹œì§€ (Core Message)**
    - ì´ íƒ€ê²Ÿ ê³ ê°ì˜ ë§ˆìŒì„ ì‚¬ë¡œì¡ì„ ìˆ˜ ìˆëŠ” í•œ ë¬¸ì¥ì˜ í•µì‹¬ì ì¸ ê´‘ê³  ë©”ì‹œì§€ëŠ” ë¬´ì—‡ì¼ê¹Œìš”?

    **ë‹¤. ì‹¤í–‰ ê°€ëŠ¥í•œ ìº í˜ì¸ ì•„ì´ë””ì–´ (Top 3)**
    - **1) (ì½˜í…ì¸ )** ë¸”ë¡œê·¸ë‚˜ ì¸ìŠ¤íƒ€ê·¸ë¨ì— ë°œí–‰í•  ì½˜í…ì¸  ì•„ì´ë””ì–´ (ì œëª© ë˜ëŠ” ì£¼ì œ í¬í•¨)
    - **2) (í”„ë¡œëª¨ì…˜)** ê²½ìŸì‚¬ì™€ ì°¨ë³„í™”ë  ìˆ˜ ìˆëŠ” ë§¤ë ¥ì ì¸ íŒë§¤ í”„ë¡œëª¨ì…˜ ì•„ì´ë””ì–´
    - **3) (ê´‘ê³ )** ë„¤ì´ë²„ ê²€ìƒ‰ ê´‘ê³ ì— ì‚¬ìš©í•  ê´‘ê³  ë¬¸êµ¬ (ì œëª©ê³¼ ì„¤ëª…)

    ---
    *ë³´ê³ ì„œëŠ” ìœ„ êµ¬ì¡°ì™€ í˜•ì‹ì„ ë°˜ë“œì‹œ ì¤€ìˆ˜í•˜ì—¬, ì „ë¬¸ê°€ì˜ ì‹œê°ìœ¼ë¡œ ì‘ì„±í•´ì£¼ì„¸ìš”.*
    """
    try:
        response = model.generate_content(prompt)
        return response.text
    except Exception as e:
        return f"AI ì „ëµ ë³´ê³ ì„œ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}"

# --- Streamlit ì•± ë©”ì¸ ë¡œì§ ---
st.title("ğŸ³ ê³ ë˜ë¯¸ ì£¼ì‹íšŒì‚¬ AI ë¹„ì¦ˆë‹ˆìŠ¤ ì¸í…”ë¦¬ì „ìŠ¤")

# --- API í‚¤ ì„¤ì • ---
g_model, n_id, n_secret = None, None, None
try:
    g_model = configure_google_ai(st.secrets["GOOGLE_API_KEY"])
    n_id = st.secrets["NAVER_CLIENT_ID"]
    n_secret = st.secrets["NAVER_CLIENT_SECRET"]
    st.sidebar.success("âœ… Google & Naver APIê°€ ì—°ê²°ë˜ì—ˆìŠµë‹ˆë‹¤.")
except KeyError as e:
    st.sidebar.error(f"âš ï¸ API í‚¤ ì„¤ì • ì˜¤ë¥˜: {e}ë¥¼ Streamlit Cloud Secretsì— ì¶”ê°€í•´ì£¼ì„¸ìš”.")
except Exception as e:
    st.sidebar.error(f"ğŸš¨ API ì—°ê²° ì‹¤íŒ¨: {e}")

# --- íƒ­ êµ¬ì„± ---
tab1, tab2, tab3 = st.tabs(["ğŸ“Š ë‚´ë¶€ ì„±ê³¼ ëŒ€ì‹œë³´ë“œ", "ğŸ“ˆ ì‹œì¥ íŠ¸ë Œë“œ ë¶„ì„ (Naver x AI)", "ğŸ’¬ AI ì–´ì‹œìŠ¤í„´íŠ¸"])


with tab1:
    st.header("ë‚´ë¶€ ì„±ê³¼ ëŒ€ì‹œë³´ë“œ", anchor=False)
    uploaded_file = st.file_uploader("ğŸ“‚ ì§€ë‚œë‹¬ íŒë§¤í˜„í™© ì—‘ì…€ íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì„¸ìš”.", type=["xlsx", "xls"], key="sales_uploader")

    if uploaded_file:
        try:
            df = pd.read_excel(uploaded_file, sheet_name="íŒë§¤í˜„í™©", header=1)
            expected_columns = ["ì¼ì-No.", "ë°°ì†¡ìƒíƒœ", "ì°½ê³ ëª…", "ê±°ë˜ì²˜ì½”ë“œ", "ê±°ë˜ì²˜ëª…", "í’ˆëª©ì½”ë“œ", "í’ˆëª©ëª…(ê·œê²©)", "ë°•ìŠ¤", "ë‚±ê°œìˆ˜ëŸ‰", "ë‹¨ê°€", "ê³µê¸‰ê°€ì•¡", "ë¶€ê°€ì„¸", "ì™¸í™”ê¸ˆì•¡", "í•©ê³„", "ì ìš”", "ì‡¼í•‘ëª°ê³ ê°ëª…", "ì‹œë¦¬ì–¼/ë¡œíŠ¸No.", "ì™¸í¬ì¥_ì—¬ë¶€", "ì „í‘œìƒíƒœ", "ì „í‘œìƒíƒœ.1", "ì¶”ê°€ë¬¸ìí˜•ì‹2", "í¬ì¥ë°•ìŠ¤", "ì¶”ê°€ìˆ«ìí˜•ì‹1", "ì‚¬ìš©ìì§€ì •ìˆ«ì1", "ì‚¬ìš©ìì§€ì •ìˆ«ì2"]
            df.columns = expected_columns[:len(df.columns)]
            numeric_cols = ["ë°•ìŠ¤", "ë‚±ê°œìˆ˜ëŸ‰", "ë‹¨ê°€", "ê³µê¸‰ê°€ì•¡", "ë¶€ê°€ì„¸", "ì™¸í™”ê¸ˆì•¡", "í•©ê³„"]
            for col in numeric_cols:
                if col in df.columns: df[col] = pd.to_numeric(df[col], errors='coerce').fillna(0)
            df['ì¼ì'] = df['ì¼ì-No.'].apply(lambda x: str(x).split('-')[0].strip() if pd.notnull(x) else None)
            df['ì¼ì'] = pd.to_datetime(df['ì¼ì'], errors='coerce', format='%Y/%m/%d')
            df.dropna(subset=['í’ˆëª©ì½”ë“œ', 'ì¼ì', 'ê±°ë˜ì²˜ëª…', 'í’ˆëª©ëª…(ê·œê²©)'], inplace=True)
            mask_static = df['í’ˆëª©ëª…(ê·œê²©)'].str.strip().isin(EXCLUDED_ITEMS)
            mask_pattern = df['í’ˆëª©ëª…(ê·œê²©)'].str.contains(EXCLUDED_KEYWORDS_PATTERN, na=False)
            combined_mask = mask_static | mask_pattern
            analysis_df = df[~combined_mask].copy()
            analysis_df['ì œí’ˆëª…'] = analysis_df['í’ˆëª©ëª…(ê·œê²©)'].apply(clean_product_name)
            analysis_df = analysis_df[analysis_df['ê±°ë˜ì²˜ëª…'].str.strip() != '']
            analysis_df = analysis_df[analysis_df['ì œí’ˆëª…'].str.strip() != '']

            st.success("ë‚´ë¶€ ë°ì´í„° ë¡œë”© ë° ì „ì²˜ë¦¬ê°€ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.")

            st.subheader("ì§€ë‚œë‹¬ í•µì‹¬ ì„±ê³¼ ì§€í‘œ", anchor=False)
            total_supply = df['ê³µê¸‰ê°€ì•¡'].sum()
            total_sales = df['í•©ê³„'].sum()
            total_export = df['ì™¸í™”ê¸ˆì•¡'].sum()
            total_boxes = analysis_df['ë°•ìŠ¤'].sum()
            unique_customers = analysis_df['ê±°ë˜ì²˜ëª…'].nunique()
            st.divider()
            col1, col2, col3, col4, col5 = st.columns(5)
            col1.metric("ì´ ê³µê¸‰ê°€ì•¡", f"{total_supply:,.0f} ì›")
            col2.metric("ì´ ë§¤ì¶œ", f"{total_sales:,.0f} ì›", help="ê³µê¸‰ê°€ì•¡ + ë¶€ê°€ì„¸")
            col3.metric("ìˆ˜ì¶œ ê¸ˆì•¡", f"{total_export:,.2f} USD")
            col4.metric("ì´ íŒë§¤ ë°•ìŠ¤", f"{total_boxes:,.0f} ê°œ")
            col5.metric("ê±°ë˜ì²˜ ìˆ˜", f"{unique_customers} ê³³")
            st.divider()

            col1, col2 = st.columns(2)
            with col1:
                st.subheader("ğŸ¢ ìƒìœ„ ê±°ë˜ì²˜ ë§¤ì¶œ (Top 10)", anchor=False)
                top_10_customers = analysis_df.groupby('ê±°ë˜ì²˜ëª…')['í•©ê³„'].sum().nlargest(10).reset_index()
                fig_bar_cust = px.bar(top_10_customers.sort_values('í•©ê³„', ascending=True), x='í•©ê³„', y='ê±°ë˜ì²˜ëª…', orientation='h', template="plotly_white", text='í•©ê³„')
                fig_bar_cust.update_traces(texttemplate='%{x:,.0f}ì›', textposition='outside')
                fig_bar_cust.update_layout(title_x=0.5, xaxis_title=None, yaxis_title=None)
                st.plotly_chart(fig_bar_cust, use_container_width=True)
            with col2:
                st.subheader("ğŸ“¦ í’ˆëª©ë³„ ë§¤ì¶œ ìˆœìœ„ (Top 10)", anchor=False)
                top_10_products = analysis_df.groupby('ì œí’ˆëª…')['í•©ê³„'].sum().nlargest(10).reset_index()
                fig_bar_prod = px.bar(top_10_products.sort_values('í•©ê³„', ascending=True), x='í•©ê³„', y='ì œí’ˆëª…', orientation='h', template="plotly_white", text='í•©ê³„')
                fig_bar_prod.update_traces(texttemplate='%{x:,.0f}ì›', textposition='outside')
                fig_bar_prod.update_layout(title_x=0.5, xaxis_title=None, yaxis_title=None)
                st.plotly_chart(fig_bar_prod, use_container_width=True)

        except Exception as e:
            st.error(f"ë‚´ë¶€ ë°ì´í„° ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {e}")

with tab2:
    st.header("ì‹œì¥ íŠ¸ë Œë“œ ë¶„ì„ (Naver x AI)", anchor=False)
    st.info("ì‹œì¥ì˜ ì‹¤ì‹œê°„ ëª©ì†Œë¦¬ë¥¼ ë“£ê³ , ë°ì´í„° ê¸°ë°˜ ë§ˆì¼€íŒ… ì „ëµì„ ìˆ˜ë¦½í•©ë‹ˆë‹¤.")
    keyword = st.text_input("ë¶„ì„í•  í‚¤ì›Œë“œë¥¼ ì…ë ¥í•˜ì„¸ìš” (ì˜ˆ: ë°€í‚¤íŠ¸, ìŠ¤í…Œì´í¬, ìº í•‘ìŒì‹)", "ë°€í‚¤íŠ¸")

    if st.button("ğŸ“ˆ ì‹œì¥ ë¶„ì„ ì‹œì‘", key="market_analysis"):
        if not all([g_model, n_id, n_secret]):
            st.warning("API í‚¤ê°€ ëª¨ë‘ ì„¤ì •ë˜ì–´ì•¼ í•©ë‹ˆë‹¤. ì‚¬ì´ë“œë°”ì˜ ì—°ê²° ìƒíƒœë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”.")
        else:
            with st.spinner(f"'{keyword}' í‚¤ì›Œë“œë¡œ ë„¤ì´ë²„ ë°ì´í„°ë¥¼ ìˆ˜ì§‘í•˜ê³  AIê°€ ë¶„ì„ ì¤‘ì…ë‹ˆë‹¤..."):
                datalab_result = call_naver_datalab(n_id, n_secret, keyword)
                shopping_result = call_naver_shopping(n_id, n_secret, keyword)

                if datalab_result and shopping_result:
                    st.subheader(f"'{keyword}' ê²€ìƒ‰ëŸ‰ íŠ¸ë Œë“œ (ìµœê·¼ 1ë…„)")
                    df_datalab = pd.DataFrame(datalab_result['results'][0]['data'])
                    df_datalab['period'] = pd.to_datetime(df_datalab['period'])
                    fig_datalab = px.line(df_datalab, x='period', y='ratio', title=f"'{keyword}' ì›”ë³„ ê²€ìƒ‰ëŸ‰ ë¹„ìœ¨", markers=True)
                    st.plotly_chart(fig_datalab, use_container_width=True)

                    st.divider()
                    st.subheader("AI ë§ˆì¼€íŒ… ì „ëµ ë³´ê³ ì„œ (by ê³ ë˜ë¯¸ AI)")
                    report = get_market_analysis_report(g_model, keyword, datalab_result, shopping_result)
                    st.markdown(report)
                else:
                    st.error("ë°ì´í„°ë¥¼ ê°€ì ¸ì˜¤ëŠ” ë° ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. API ì„¤ì •ì´ë‚˜ í‚¤ì›Œë“œë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”.")

with tab3:
    st.header("AI ì–´ì‹œìŠ¤í„´íŠ¸ (ë‚´ë¶€ ë°ì´í„° ì§ˆë¬¸)", anchor=False)
    st.info("ì—…ë¡œë“œëœ ì—‘ì…€ íŒŒì¼ì˜ ë‚´ìš©ì— ëŒ€í•´ ê¶ê¸ˆí•œ ì ì„ ì§ˆë¬¸í•´ë³´ì„¸ìš”.")
    # (ì„¸ì…˜ ê´€ë¦¬ ë° ì±„íŒ… ë¡œì§ì€ ì´ì „ê³¼ ë™ì¼í•˜ê²Œ ìœ ì§€)
