import streamlit as st
import pandas as pd
import plotly.express as px
import plotly.graph_objects as go
from io import BytesIO
import google.generativeai as genai
import re
import requests
import json
from datetime import datetime, timedelta

# --- Streamlit í˜ì´ì§€ ì„¤ì • ---
st.set_page_config(
    page_title="ê³ ë˜ë¯¸ ì£¼ì‹íšŒì‚¬ AI ë¹„ì¦ˆë‹ˆìŠ¤ ì¸í…”ë¦¬ì „ìŠ¤",
    page_icon="ğŸ³",
    layout="wide"
)

# --- ì‚¬ìš©ì ì •ì˜ ì˜ì—­ ---
EXCLUDED_ITEMS = [
    "ê²½ì˜ì§€ì›ë¶€ ê¸°íƒ€ì½”ë“œ", "ì¶”ê°€í• ì¸", "í”½ì—…í• ì¸",
    "KPP íŒŒë ›íŠ¸(ë¹¨ê°„ìƒ‰) (N11)", "KPP íŒŒë ›íŠ¸(íŒŒë€ìƒ‰) (N12)",
    "KPP íŒŒë ›íŠ¸ (ë¹¨ê°„ìƒ‰)", "KPP íŒŒë ›íŠ¸ (íŒŒë€ìƒ‰)",
    "[ë¶€ì¬ë£Œ]NO.320_80gì „ìš©_íŠ¸ë ˆì´_í™ˆí”ŒëŸ¬ìŠ¤ì „ìš©_KCP",
    "ë¯¸ë‹ˆë½êµ 20g ì´ì—” (ì„¸íŠ¸ìƒí’ˆ)", "ì´ˆëŒ€ë¦¬ 50g ì£¼ë¹„ (ì„¸íŠ¸ìƒí’ˆ)"
]
EXCLUDED_KEYWORDS_PATTERN = r'íƒë°°ë¹„|ìš´ì†¡ë¹„|ìˆ˜ìˆ˜ë£Œ|ì¿ í°í• ì¸|ì¶”ê°€í• ì¸|í”½ì—…í• ì¸'

# --- ë°ì´í„° í´ë¦¬ë‹ ë° AI í•¨ìˆ˜ ---
def clean_product_name(name):
    if not isinstance(name, str): return name
    name = re.sub(r'\[ì™„ì œí’ˆ\]|ê³ ë˜ë¯¸|ì„¤ë˜ë‹´', '', name, flags=re.I).strip()
    spec_full = ''
    match = re.search(r'\[(.*?)\]|\((.*?)\)', name)
    if match:
        spec_full = (match.group(1) or match.group(2) or '').strip()
        name = re.sub(r'\[.*?\]|\(.*?\)', '', name).strip()
    storage = 'ëƒ‰ë™' if 'ëƒ‰ë™' in spec_full else 'ëƒ‰ì¥' if 'ëƒ‰ì¥' in spec_full else ''
    spec = re.sub(r'ëƒ‰ë™|ëƒ‰ì¥|\*|1ea|=|1kg', '', spec_full, flags=re.I).strip()
    name = re.sub(r'[_]', ' ', name).strip()
    spec = re.sub(r'[_]', ' ', spec).strip()
    name = re.sub(r'\s+', ' ', name).strip()
    spec = re.sub(r'\s+', ' ', spec).strip()
    if spec and storage: return f"{name} ({spec}) {storage}"
    elif spec: return f"{name} ({spec})"
    elif storage: return f"{name} {storage}"
    else: return name

def configure_google_ai(api_key):
    try:
        genai.configure(api_key=api_key)
        model = genai.GenerativeModel('gemini-1.5-flash')
        return model
    except Exception as e:
        st.error(f"Google AI ëª¨ë¸ ì„¤ì •ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤: {e}")
        st.stop()

def get_overall_strategy_report(model, df):
    if model is None: return "AI ëª¨ë¸ì´ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."
    total_supply = df[df['í•©ê³„'] >= 0]['ê³µê¸‰ê°€ì•¡'].sum()
    total_sales = df[df['í•©ê³„'] >= 0]['í•©ê³„'].sum()
    unique_customers = df['ê±°ë˜ì²˜ëª…'].nunique()
    prompt = f"""
    ë‹¹ì‹ ì€ 'ê³ ë˜ë¯¸ ì£¼ì‹íšŒì‚¬'ì˜ ìˆ˜ì„ ë¹„ì¦ˆë‹ˆìŠ¤ ì „ëµê°€ **'ê³ ë˜ë¯¸ AI'** ì…ë‹ˆë‹¤.
    ì§€ë‚œë‹¬ íŒë§¤ ë°ì´í„°ë¥¼ ë¶„ì„í•˜ì—¬, ê²½ì˜ì§„ì´ ë‹¤ìŒ ë‹¬ì˜ ë°©í–¥ì„ ê²°ì •í•  ìˆ˜ ìˆë„ë¡ ëª…í™•í•˜ê³  êµ¬ì¡°í™”ëœ ì „ëµ ë³´ê³ ì„œë¥¼ ì‘ì„±í•´ì£¼ì„¸ìš”.

    **[ì¤‘ìš”] ì•„ë˜ ì œê³µëœ 'ì§€ë‚œë‹¬ í•µì‹¬ ì„±ê³¼ ì§€í‘œ'ë¥¼ ë°˜ë“œì‹œ ê·¸ëŒ€ë¡œ ì‚¬ìš©í•˜ì—¬ ë³´ê³ ì„œë¥¼ ì‘ì„±í•˜ì„¸ìš”.**

    ### ì§€ë‚œë‹¬ í•µì‹¬ ì„±ê³¼ ì§€í‘œ
    - **ì´ ê³µê¸‰ê°€ì•¡:** {total_supply:,.0f} ì›
    - **ì´ ë§¤ì¶œ:** {total_sales:,.0f} ì›
    - **ê±°ë˜ì²˜ ìˆ˜:** {unique_customers} ê³³
    - **íŒë§¤ ê¸°ê°„:** {df['ì¼ì'].min().strftime('%Y-%m-%d')} ~ {df['ì¼ì'].max().strftime('%Y-%m-%d')}

    ### ë‹¤ìŒ ë‹¬ ì „ëµ ë³´ê³ ì„œ
    
    **1. ì›”ê°„ ì„±ê³¼ ìš”ì•½ (Executive Summary)**
    - ìœ„ í•µì‹¬ ì„±ê³¼ ì§€í‘œë¥¼ ë°”íƒ•ìœ¼ë¡œ ì§€ë‚œë‹¬ì˜ ì „ë°˜ì ì¸ ì„±ê³¼ë¥¼ 2~3ë¬¸ì¥ìœ¼ë¡œ ìš”ì•½í•´ì£¼ì„¸ìš”.

    **2. ì˜í•œ ì  (What Went Well)**
    - **íš¨ì ìƒí’ˆ:** ë§¤ì¶œì•¡ ê¸°ì¤€ ìƒìœ„ 3ê°œ ì œí’ˆì„ ì–¸ê¸‰í•˜ê³ , ì´ ì œí’ˆë“¤ì´ ì„±ê³µí•œ ì´ìœ ë¥¼ ë°ì´í„°ì— ê¸°ë°˜í•˜ì—¬ ë¶„ì„í•´ì£¼ì„¸ìš”.
    - **í•µì‹¬ ê³ ê°:** ë§¤ì¶œì•¡ ê¸°ì¤€ ìƒìœ„ 3ê°œ ê±°ë˜ì²˜ë¥¼ ì–¸ê¸‰í•˜ê³ , ì´ë“¤ê³¼ì˜ ê´€ê³„ê°€ ë¹„ì¦ˆë‹ˆìŠ¤ì— ì–´ë–¤ ê¸ì •ì  ì˜í–¥ì„ ë¯¸ì³¤ëŠ”ì§€ ì„¤ëª…í•´ì£¼ì„¸ìš”.

    **3. ê°œì„ í•  ì  (Areas for Improvement)**
    - **ì„±ì¥ í•„ìš” ìƒí’ˆ:** íŒë§¤ê°€ ë¶€ì§„í–ˆë˜ í•˜ìœ„ ì œí’ˆêµ°ì´ë‚˜ íŠ¹ì • ì¹´í…Œê³ ë¦¬ë¥¼ ì–¸ê¸‰í•˜ê³ , ì´ê²ƒì´ ì „ì²´ ì‹¤ì ì— ë¯¸ì¹œ ì˜í–¥ì„ ê°„ëµíˆ ë¶„ì„í•´ì£¼ì„¸ìš”.
    - **ì ì¬ ë¦¬ìŠ¤í¬:** íŠ¹ì • ê±°ë˜ì²˜ë‚˜ ì œí’ˆì— ëŒ€í•œ ë§¤ì¶œ ì˜ì¡´ë„ê°€ ë†’ë‹¤ë©´ ê·¸ ìœ„í—˜ì„±ì„ ì§€ì í•˜ê³ , ê³ ê° ë‹¤ë³€í™”ì˜ í•„ìš”ì„±ì„ ì œê¸°í•´ì£¼ì„¸ìš”.

    **4. ë‹¤ìŒ ë‹¬ í•µì‹¬ ì‹¤í–‰ ê³¼ì œ (Action Items for Next Month)**
    - ìœ„ ë¶„ì„ì„ ë°”íƒ•ìœ¼ë¡œ, ë‹¤ìŒ ë‹¬ì— ì¦‰ì‹œ ì‹¤í–‰í•´ì•¼ í•  ê°€ì¥ ì¤‘ìš”í•œ ì•¡ì…˜ ì•„ì´í…œ 3ê°€ì§€ë¥¼ ìš°ì„ ìˆœìœ„ì™€ í•¨ê»˜ êµ¬ì²´ì ìœ¼ë¡œ ì œì•ˆí•´ì£¼ì„¸ìš”.
      - ì˜ˆ: (1ìˆœìœ„) **íš¨ì ìƒí’ˆ A í”„ë¡œëª¨ì…˜ ê°•í™”:** Bê³ ê°ì‚¬ë¥¼ ëŒ€ìƒìœ¼ë¡œ Aìƒí’ˆ 10+1 í”„ë¡œëª¨ì…˜ì„ ì œì•ˆí•˜ì—¬ ë§¤ì¶œ 15% ì¦ëŒ€ ëª©í‘œ.
      - ì˜ˆ: (2ìˆœìœ„) **ì‹ ê·œ ê³ ê° í™•ë³´:** Cì§€ì—­ì˜ ìœ ì‚¬ ì‹ë‹¹ì„ íƒ€ê²Ÿìœ¼ë¡œ ì‹ ì œí’ˆ D ìƒ˜í”Œ ì œê³µ ë° ì´ˆê¸° í• ì¸ í˜œíƒ ë¶€ì—¬.
      - ì˜ˆ: (3ìˆœìœ„) **ì¬ê³  ê´€ë¦¬ ìµœì í™”:** íŒë§¤ ë¶€ì§„ ìƒí’ˆ Eì˜ ì¬ê³  ì†Œì§„ì„ ìœ„í•œ ë¬¶ìŒ í• ì¸ ê¸°íš.

    ---
    *ë³´ê³ ì„œëŠ” ìœ„ êµ¬ì¡°ì™€ í˜•ì‹ì„ ë°˜ë“œì‹œ ì¤€ìˆ˜í•˜ì—¬, **êµµì€ ê¸€ì”¨**ì™€ ê¸€ë¨¸ë¦¬ ê¸°í˜¸(-)ë¥¼ ì‚¬ìš©í•´ ê°€ë…ì„±ì„ ë†’ì—¬ì£¼ì„¸ìš”.*
    """
    try:
        response = model.generate_content(prompt)
        return response.text
    except Exception as e: return f"AI ë¦¬í¬íŠ¸ ìƒì„± ì¤‘ ì˜¤ë¥˜: {e}"

def call_naver_datalab(api_id, api_secret, keyword):
    end_date = datetime.today().strftime('%Y-%m-%d')
    start_date = (datetime.today() - timedelta(days=365)).strftime('%Y-%m-%d')
    body = {"startDate": start_date, "endDate": end_date, "timeUnit": "month", "keywordGroups": [{"groupName": keyword, "keywords": [keyword]}]}
    url = "https://openapi.naver.com/v1/datalab/search"
    headers = {"X-Naver-Client-Id": api_id, "X-Naver-Client-Secret": api_secret, "Content-Type": "application/json"}
    try:
        response = requests.post(url, headers=headers, data=json.dumps(body))
        response.raise_for_status()
        return response.json()
    except requests.exceptions.RequestException as e:
        st.error(f"ë„¤ì´ë²„ ë°ì´í„°ë© API í˜¸ì¶œ ì˜¤ë¥˜: {e}")
        return None

def call_naver_shopping(api_id, api_secret, keyword):
    url = f"https://openapi.naver.com/v1/search/shop.json?query={keyword}&display=5"
    headers = {"X-Naver-Client-Id": api_id, "X-Naver-Client-Secret": api_secret}
    try:
        response = requests.get(url, headers=headers)
        response.raise_for_status()
        return response.json()
    except requests.exceptions.RequestException as e:
        st.error(f"ë„¤ì´ë²„ ì‡¼í•‘ API í˜¸ì¶œ ì˜¤ë¥˜: {e}")
        return None

def get_product_deep_dive_report(model, product_name, internal_rank, datalab_result, shopping_result):
    if model is None: return "AI ëª¨ë¸ì´ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."

    # --- AI í”„ë¡¬í”„íŠ¸ ì•ˆì •ì„± ê°•í™” ---
    trend_data_section = "**ê²€ìƒ‰ëŸ‰ íŠ¸ë Œë“œ ë°ì´í„° ì—†ìŒ**"
    if datalab_result and datalab_result.get('results') and datalab_result['results'][0].get('data'):
        trend_data_section = f"""- **ê²€ìƒ‰ëŸ‰ íŠ¸ë Œë“œ (ìµœê·¼ 1ë…„):** {json.dumps(datalab_result['results'][0]['data'], ensure_ascii=False)}
    *(ë°ì´í„°ì—ì„œ ë‚˜íƒ€ë‚˜ëŠ” ê³„ì ˆì  ì„±ìˆ˜ê¸°, ë¹„ìˆ˜ê¸°ë¥¼ ë¶„ì„ì— í™œìš©í•˜ì„¸ìš”.)*"""

    shopping_data_section = "**ì‡¼í•‘ ê²€ìƒ‰ ë°ì´í„° ì—†ìŒ**"
    if shopping_result and shopping_result.get('items'):
        shopping_data_section = f"""- **ì£¼ìš” ê²½ìŸ ì œí’ˆ (ìƒìœ„ 5ê°œ):**
    ```
    {pd.DataFrame(shopping_result['items'])[['title', 'lprice', 'brand']].to_string()}
    ```
    *(ê²½ìŸ ì œí’ˆì˜ ë„¤ì´ë°, ê°€ê²©ëŒ€ë¥¼ ë¶„ì„ì— í™œìš©í•˜ì„¸ìš”.)*"""

    prompt = f"""
    ë‹¹ì‹ ì€ ëŒ€í•œë¯¼êµ­ ìµœê³ ì˜ ë°ì´í„° ê¸°ë°˜ ë§ˆì¼€í„° **'ê³ ë˜ë¯¸ AI'** ì…ë‹ˆë‹¤.
    ìš°ë¦¬ì˜ ì œí’ˆì¸ **'{product_name}'**ì— ëŒ€í•œ **ë‚´ë¶€ íŒë§¤ ë°ì´í„°**ì™€ **ì™¸ë¶€ ì‹œì¥ ë°ì´í„°**ë¥¼ ì¢…í•©í•˜ì—¬, ì‹¬ì¸µ ë¶„ì„ ë° ë§ˆì¼€íŒ… ì „ëµì„ ìˆ˜ë¦½í•´ì£¼ì„¸ìš”.

    ### 1. ë°ì´í„° ì¢…í•© ë¶„ì„ (Data Synthesis)

    **ê°€. ë‚´ë¶€ ì„±ê³¼ (Internal Performance)**
    - **íŒë§¤ ìˆœìœ„:** ìš°ë¦¬ íšŒì‚¬ ì „ì²´ ì œí’ˆ ì¤‘ ë§¤ì¶œ **{internal_rank}ìœ„**ì˜ í•µì‹¬ ì œí’ˆì…ë‹ˆë‹¤.

    **ë‚˜. ì™¸ë¶€ ì‹œì¥ í˜„í™© (External Market - Source: Naver API)**
    {trend_data_section}
    {shopping_data_section}

    ### 2. '{product_name}' ì‹¬ì¸µ ë¶„ì„ ë° ì „ëµ ì œì•ˆ

    ìœ„ ë°ì´í„°ë¥¼ ë°”íƒ•ìœ¼ë¡œ, ì•„ë˜ í•­ëª©ì— ëŒ€í•´ êµ¬ì²´ì ì¸ ë³´ê³ ì„œë¥¼ ì‘ì„±í•´ì£¼ì„¸ìš”.

    **ê°€. SWOT ë¶„ì„**
    - **Strength (ê°•ì ):** ë‚´ë¶€ ì„±ê³¼(ì˜ˆ: ë†’ì€ íŒë§¤ ìˆœìœ„)ë¥¼ ë°”íƒ•ìœ¼ë¡œ í•œ ê°•ì ì€ ë¬´ì—‡ì¸ê°€?
    - **Weakness (ì•½ì ):** ê²½ìŸì‚¬ ëŒ€ë¹„ ê°€ê²©, ë¸Œëœë“œ ì¸ì§€ë„ ë“±ì—ì„œ ì•½ì ì€ ë¬´ì—‡ì¸ê°€?
    - **Opportunity (ê¸°íšŒ):** ê²€ìƒ‰ëŸ‰ íŠ¸ë Œë“œ(ì˜ˆ: íŠ¹ì • ì‹œì¦Œì˜ ê²€ìƒ‰ëŸ‰ ê¸‰ë“±)ì—ì„œ ë°œê²¬ë˜ëŠ” ê¸°íšŒëŠ” ë¬´ì—‡ì¸ê°€?
    - **Threat (ìœ„í˜‘):** ê°•ë ¥í•œ ê²½ìŸ ì œí’ˆì˜ ì¡´ì¬, ë¹„ìˆ˜ê¸° ë“± ìœ„í˜‘ ìš”ì¸ì€ ë¬´ì—‡ì¸ê°€?

    **ë‚˜. ë‹¤ìŒ ë‹¬ ë§ˆì¼€íŒ… ì•¡ì…˜ í”Œëœ (Action Plan for Next Month)**
    - **1) íƒ€ê²Ÿ ê³ ê°:** ì–´ë–¤ ê³ ê°ì„ ì§‘ì¤‘ ê³µëµí•´ì•¼ í•˜ëŠ”ê°€?
    - **2) í•µì‹¬ ë©”ì‹œì§€:** ê·¸ë“¤ì—ê²Œ ì–´ë–¤ ì ì„ ê°€ì¥ ê°•ë ¥í•˜ê²Œ ì–´í•„í•´ì•¼ í•˜ëŠ”ê°€? (ì˜ˆ: "ìš°ë¦¬ ë§¤ì¥ íŒë§¤ 1ìœ„!", "ì§€ê¸ˆ ê°€ì¥ ë§ì´ ì°¾ëŠ” ë°”ë¡œ ê·¸ ì œí’ˆ!")
    - **3) ì¶”ì²œ ìº í˜ì¸:** ìœ„ ë¶„ì„ì„ ë°”íƒ•ìœ¼ë¡œ, ë°”ë¡œ ì‹¤í–‰í•  ìˆ˜ ìˆëŠ” ì˜¨ë¼ì¸ ë§ˆì¼€íŒ… ìº í˜ì¸ 1ê°€ì§€ë¥¼ êµ¬ì²´ì ìœ¼ë¡œ ì œì•ˆí•´ì£¼ì„¸ìš”.

    ---
    *ë³´ê³ ì„œëŠ” ìœ„ êµ¬ì¡°ì™€ í˜•ì‹ì„ ë°˜ë“œì‹œ ì¤€ìˆ˜í•˜ì—¬, ì „ë¬¸ê°€ì˜ ì‹œê°ìœ¼ë¡œ ì‘ì„±í•´ì£¼ì„¸ìš”.*
    """
    try:
        response = model.generate_content(prompt)
        return response.text
    except Exception as e: return f"AI ì „ëµ ë³´ê³ ì„œ ìƒì„± ì¤‘ ì˜¤ë¥˜: {e}"

def get_ai_answer(model, df, question):
    if model is None: return "AI ëª¨ë¸ì´ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."
    prompt = f"""
    ë‹¹ì‹ ì€ 'ê³ ë˜ë¯¸ ì£¼ì‹íšŒì‚¬'ì˜ íŒë§¤ ë°ì´í„°ë¥¼ ì¡°íšŒí•˜ëŠ” ì¹œì ˆí•œ AI ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤.
    ì•„ë˜ ì œê³µëœ ì „ì²´ íŒë§¤ ë°ì´í„°ë¥¼ ì°¸ê³ í•˜ì—¬ ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— ë‹µë³€í•´ì£¼ì„¸ìš”.
    **ë°ì´í„°:**
    ```
    {df.to_string()}
    ```
    **ì‚¬ìš©ì ì§ˆë¬¸:** {question}
    **ë‹µë³€ ê°€ì´ë“œë¼ì¸:**
    - ë°˜ë“œì‹œ ì œê³µëœ ë°ì´í„°ì— ê·¼ê±°í•˜ì—¬ ë‹µë³€í•´ì•¼ í•©ë‹ˆë‹¤.
    - ë°ì´í„°ì— ì—†ëŠ” ë‚´ìš©ì€ 'ë°ì´í„°ì— ì •ë³´ê°€ ì—†ìŠµë‹ˆë‹¤'ë¼ê³  ëª…í™•íˆ ë°í˜€ì£¼ì„¸ìš”.
    - ê°€ëŠ¥í•œ í•œ ì§ˆë¬¸ì˜ ìš”ì§€ì— ë§ê²Œ ê°„ê²°í•˜ê³  ì •í™•í•˜ê²Œ ë‹µë³€í•´ì£¼ì„¸ìš”.
    - ê³„ì‚°ì´ í•„ìš”í•œ ê²½ìš°, ì§ì ‘ ê³„ì‚°í•˜ì—¬ ë‹µë³€í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
    """
    try:
        response = model.generate_content(prompt)
        return response.text
    except Exception as e: return f"AI ë‹µë³€ ìƒì„± ì¤‘ ì˜¤ë¥˜: {e}"

# --- Streamlit ì•± ë©”ì¸ ë¡œì§ ---
st.title("ğŸ³ ê³ ë˜ë¯¸ ì£¼ì‹íšŒì‚¬ AI ë¹„ì¦ˆë‹ˆìŠ¤ ì¸í…”ë¦¬ì „ìŠ¤")

g_model, n_id, n_secret = None, None, None
try:
    g_model = configure_google_ai(st.secrets["GOOGLE_API_KEY"])
    n_id = st.secrets["NAVER_CLIENT_ID"]
    n_secret = st.secrets["NAVER_CLIENT_SECRET"]
    st.sidebar.success("âœ… Google & Naver APIê°€ ì—°ê²°ë˜ì—ˆìŠµë‹ˆë‹¤.")
except KeyError as e:
    st.sidebar.error(f"âš ï¸ API í‚¤ ì„¤ì • ì˜¤ë¥˜: {e}ë¥¼ Secretsì— ì¶”ê°€í•´ì£¼ì„¸ìš”.")
except Exception as e:
    st.sidebar.error(f"ğŸš¨ API ì—°ê²° ì‹¤íŒ¨: {e}")

if 'analysis_df' not in st.session_state: st.session_state.analysis_df = None
if 'full_df' not in st.session_state: st.session_state.full_df = None

with st.sidebar:
    st.header("ë°ì´í„° ì—…ë¡œë“œ")
    uploaded_file = st.file_uploader("ğŸ“‚ íŒë§¤í˜„í™© ì—‘ì…€ íŒŒì¼ì„ ì—¬ê¸°ì— ì—…ë¡œë“œí•˜ì„¸ìš”.", type=["xlsx", "xls"])
    if uploaded_file:
        with st.spinner("ë°ì´í„°ë¥¼ ì²˜ë¦¬í•˜ëŠ” ì¤‘ì…ë‹ˆë‹¤..."):
            try:
                df = pd.read_excel(uploaded_file, sheet_name="íŒë§¤í˜„í™©", header=1)
                expected_columns = ["ì¼ì-No.", "ë°°ì†¡ìƒíƒœ", "ì°½ê³ ëª…", "ê±°ë˜ì²˜ì½”ë“œ", "ê±°ë˜ì²˜ëª…", "í’ˆëª©ì½”ë“œ", "í’ˆëª©ëª…(ê·œê²©)", "ë°•ìŠ¤", "ë‚±ê°œìˆ˜ëŸ‰", "ë‹¨ê°€", "ê³µê¸‰ê°€ì•¡", "ë¶€ê°€ì„¸", "ì™¸í™”ê¸ˆì•¡", "í•©ê³„", "ì ìš”", "ì‡¼í•‘ëª°ê³ ê°ëª…", "ì‹œë¦¬ì–¼/ë¡œíŠ¸No.", "ì™¸í¬ì¥_ì—¬ë¶€", "ì „í‘œìƒíƒœ", "ì „í‘œìƒíƒœ.1", "ì¶”ê°€ë¬¸ìí˜•ì‹2", "í¬ì¥ë°•ìŠ¤", "ì¶”ê°€ìˆ«ìí˜•ì‹1", "ì‚¬ìš©ìì§€ì •ìˆ«ì1", "ì‚¬ìš©ìì§€ì •ìˆ«ì2"]
                df.columns = expected_columns[:len(df.columns)]
                numeric_cols = ["ë°•ìŠ¤", "ë‚±ê°œìˆ˜ëŸ‰", "ë‹¨ê°€", "ê³µê¸‰ê°€ì•¡", "ë¶€ê°€ì„¸", "ì™¸í™”ê¸ˆì•¡", "í•©ê³„"]
                for col in numeric_cols:
                    if col in df.columns: df[col] = pd.to_numeric(df[col], errors='coerce').fillna(0)
                df['ì¼ì'] = df['ì¼ì-No.'].apply(lambda x: str(x).split('-')[0].strip() if pd.notnull(x) else None)
                df['ì¼ì'] = pd.to_datetime(df['ì¼ì'], errors='coerce', format='%Y/%m/%d')
                df.dropna(subset=['í’ˆëª©ì½”ë“œ', 'ì¼ì', 'ê±°ë˜ì²˜ëª…', 'í’ˆëª©ëª…(ê·œê²©)'], inplace=True)
                mask_static = df['í’ˆëª©ëª…(ê·œê²©)'].str.strip().isin(EXCLUDED_ITEMS)
                mask_pattern = df['í’ˆëª©ëª…(ê·œê²©)'].str.contains(EXCLUDED_KEYWORDS_PATTERN, na=False)
                combined_mask = mask_static | mask_pattern
                analysis_df = df[~combined_mask].copy()
                analysis_df['ì œí’ˆëª…'] = analysis_df['í’ˆëª©ëª…(ê·œê²©)'].apply(clean_product_name)
                analysis_df = analysis_df[analysis_df['ê±°ë˜ì²˜ëª…'].str.strip() != '']
                analysis_df = analysis_df[analysis_df['ì œí’ˆëª…'].str.strip() != '']
                st.session_state.analysis_df = analysis_df
                st.session_state.full_df = df
                st.success("ë°ì´í„° ì²˜ë¦¬ê°€ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!")
            except Exception as e:
                st.error(f"ë°ì´í„° ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {e}")
                st.session_state.analysis_df = None
                st.session_state.full_df = None

tab1, tab2, tab3, tab4 = st.tabs(["[1] ë‚´ë¶€ ì„±ê³¼ ìš”ì•½", "[2] AI ì¢…í•© ì „ëµ ë¦¬í¬íŠ¸", "[3] ì œí’ˆ ì‹¬ì¸µ ë¶„ì„ (ì‹œì¥ ì—°ë™)", "[4. AI ì–´ì‹œìŠ¤í„´íŠ¸]"])

if st.session_state.analysis_df is None:
    st.info("ğŸ‘ˆ ì‚¬ì´ë“œë°”ì—ì„œ íŒë§¤í˜„í™© ì—‘ì…€ íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì—¬ ë¶„ì„ì„ ì‹œì‘í•˜ì„¸ìš”.")
else:
    analysis_df = st.session_state.analysis_df
    df = st.session_state.full_df

    with tab1:
        st.header("[1] ì§€ë‚œë‹¬ í•µì‹¬ ì„±ê³¼ ìš”ì•½", anchor=False)
        total_supply = df['ê³µê¸‰ê°€ì•¡'].sum()
        total_sales = df['í•©ê³„'].sum()
        total_export = df['ì™¸í™”ê¸ˆì•¡'].sum()
        total_boxes = analysis_df['ë°•ìŠ¤'].sum()
        unique_customers = analysis_df['ê±°ë˜ì²˜ëª…'].nunique()
        st.divider()
        col1, col2, col3, col4, col5 = st.columns(5)
        col1.metric("ì´ ê³µê¸‰ê°€ì•¡", f"{total_supply:,.0f} ì›")
        col2.metric("ì´ ë§¤ì¶œ", f"{total_sales:,.0f} ì›", help="ê³µê¸‰ê°€ì•¡ + ë¶€ê°€ì„¸")
        col3.metric("ìˆ˜ì¶œ ê¸ˆì•¡", f"{total_export:,.2f} USD")
        col4.metric("ì´ íŒë§¤ ë°•ìŠ¤", f"{total_boxes:,.0f} ê°œ")
        col5.metric("ê±°ë˜ì²˜ ìˆ˜", f"{unique_customers} ê³³")
        st.divider()

        col1, col2 = st.columns(2)
        with col1:
            st.subheader("ğŸ¢ ìƒìœ„ ê±°ë˜ì²˜ ë§¤ì¶œ (Top 10)", anchor=False)
            top_10_customers = analysis_df.groupby('ê±°ë˜ì²˜ëª…')['í•©ê³„'].sum().nlargest(10).reset_index()
            fig_bar_cust = px.bar(top_10_customers.sort_values('í•©ê³„', ascending=True), x='í•©ê³„', y='ê±°ë˜ì²˜ëª…', orientation='h', template="plotly_white", text='í•©ê³„')
            fig_bar_cust.update_traces(texttemplate='%{x:,.0f}ì›', textposition='outside')
            fig_bar_cust.update_layout(title_x=0.5, xaxis_title=None, yaxis_title=None)
            st.plotly_chart(fig_bar_cust, use_container_width=True)
        with col2:
            st.subheader("ğŸ“¦ í’ˆëª©ë³„ ë§¤ì¶œ ìˆœìœ„ (Top 10)", anchor=False)
            top_10_products = analysis_df.groupby('ì œí’ˆëª…')['í•©ê³„'].sum().nlargest(10).reset_index()
            fig_bar_prod = px.bar(top_10_products.sort_values('í•©ê³„', ascending=True), x='í•©ê³„', y='ì œí’ˆëª…', orientation='h', template="plotly_white", text='í•©ê³„')
            fig_bar_prod.update_traces(texttemplate='%{x:,.0f}ì›', textposition='outside')
            fig_bar_prod.update_layout(title_x=0.5, xaxis_title=None, yaxis_title=None)
            st.plotly_chart(fig_bar_prod, use_container_width=True)
    
    with tab2:
        st.header("[2] AI ì¢…í•© ì „ëµ ë¦¬í¬íŠ¸ (ë‚´ë¶€ ë°ì´í„° ê¸°ë°˜)", anchor=False)
        st.info("ì§€ë‚œë‹¬ ë‚´ë¶€ íŒë§¤ ì‹¤ì ì„ ë°”íƒ•ìœ¼ë¡œ AIê°€ ë¹„ì¦ˆë‹ˆìŠ¤ ì „ëµì„ ìˆ˜ë¦½í•©ë‹ˆë‹¤.")
        if st.button("ğŸ“ˆ ì¢…í•© ì „ëµ ë¦¬í¬íŠ¸ ìƒì„±", key="overall_strategy"):
            if g_model:
                with st.spinner("ê³ ë˜ë¯¸ AIê°€ ë‚´ë¶€ ë°ì´í„°ë¥¼ ë¶„ì„í•˜ì—¬ ì¢…í•© ì „ëµì„ ìˆ˜ë¦½í•˜ê³  ìˆìŠµë‹ˆë‹¤..."):
                    report = get_overall_strategy_report(g_model, analysis_df)
                    st.markdown(report)
            else: st.warning("AI ëª¨ë¸ì´ ì—°ê²°ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")

    with tab3:
        st.header("[3] ì œí’ˆ ì‹¬ì¸µ ë¶„ì„ (ì‹œì¥ ì—°ë™)", anchor=False)
        st.info("ìš°ë¦¬ ì œí’ˆê³¼ ì™¸ë¶€ ì‹œì¥ ë°ì´í„°ë¥¼ ê²°í•©í•˜ì—¬, ì œí’ˆë³„ ë§ì¶¤ ë§ˆì¼€íŒ… ì „ëµì„ ë„ì¶œí•©ë‹ˆë‹¤.")
        
        product_list = sorted(analysis_df['ì œí’ˆëª…'].unique())
        selected_product = st.selectbox("ë¶„ì„í•  ì œí’ˆì„ ì„ íƒí•˜ì„¸ìš”.", product_list)

        if st.button(f"'{selected_product}' ì‹œì¥ ë¶„ì„ ì‹œì‘", key="deep_dive"):
            if not all([g_model, n_id, n_secret]):
                st.warning("API í‚¤ê°€ ëª¨ë‘ ì„¤ì •ë˜ì–´ì•¼ í•©ë‹ˆë‹¤.")
            else:
                with st.spinner(f"'{selected_product}'ì— ëŒ€í•œ ë‚´/ì™¸ë¶€ ë°ì´í„°ë¥¼ ì¢…í•© ë¶„ì„ ì¤‘ì…ë‹ˆë‹¤..."):
                    product_ranks = analysis_df.groupby('ì œí’ˆëª…')['í•©ê³„'].sum().rank(method='dense', ascending=False).astype(int)
                    internal_rank = product_ranks.get(selected_product, 'ìˆœìœ„ê¶Œ ì™¸')
                    
                    datalab_result = call_naver_datalab(n_id, n_secret, selected_product)
                    shopping_result = call_naver_shopping(n_id, n_secret, selected_product)

                    st.subheader(f"'{selected_product}' ì‹œì¥ ë°ì´í„° ë¶„ì„")
                    col1, col2 = st.columns(2)
                    
                    # --- ì˜¤ë¥˜ ìˆ˜ì •: ë°ì´í„° ìœ íš¨ì„± ê²€ì‚¬ í›„ ì°¨íŠ¸ ìƒì„± ---
                    with col1:
                        st.markdown("**ë„¤ì´ë²„ ê²€ìƒ‰ëŸ‰ íŠ¸ë Œë“œ (1ë…„)**")
                        if datalab_result and datalab_result.get('results') and datalab_result['results'][0].get('data'):
                            df_datalab = pd.DataFrame(datalab_result['results'][0]['data'])
                            df_datalab['period'] = pd.to_datetime(df_datalab['period'])
                            fig_datalab = px.line(df_datalab, x='period', y='ratio', markers=True)
                            fig_datalab.update_layout(yaxis_title="ìƒëŒ€ì  ê²€ìƒ‰ëŸ‰", xaxis_title=None)
                            st.plotly_chart(fig_datalab, use_container_width=True)
                        else:
                            st.warning(f"'{selected_product}'ì— ëŒ€í•œ ë„¤ì´ë²„ ê²€ìƒ‰ëŸ‰ íŠ¸ë Œë“œ ë°ì´í„°ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                    with col2:
                        st.markdown("**ë„¤ì´ë²„ ì‡¼í•‘ ê²½ìŸ ì œí’ˆ (ìƒìœ„ 5ê°œ)**")
                        if shopping_result and shopping_result.get('items'):
                            df_shopping = pd.DataFrame(shopping_result['items'])[['title', 'lprice', 'brand']]
                            df_shopping.rename(columns={'title': 'ì œí’ˆëª…', 'lprice': 'ìµœì €ê°€(ì›)', 'brand': 'ë¸Œëœë“œ'}, inplace=True)
                            st.dataframe(df_shopping, use_container_width=True)
                        else:
                            st.warning(f"'{selected_product}'ì— ëŒ€í•œ ë„¤ì´ë²„ ì‡¼í•‘ ë°ì´í„°ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                    
                    st.divider()
                    st.subheader("AI ì‹¬ì¸µ ë¶„ì„ ë° ì „ëµ ì œì•ˆ (by ê³ ë˜ë¯¸ AI)")
                    report = get_product_deep_dive_report(g_model, selected_product, internal_rank, datalab_result, shopping_result)
                    st.markdown(report)

    with tab4:
        st.header("[4] AI ì–´ì‹œìŠ¤í„´íŠ¸ (ì „ì²´ ë°ì´í„° ì§ˆë¬¸)", anchor=False)
        st.info("ì—‘ì…€ ì›ë³¸ ë°ì´í„° ì „ì²´ì— ëŒ€í•´ ê¶ê¸ˆí•œ ì ì„ ì§ˆë¬¸í•´ë³´ì„¸ìš”. (í• ì¸, ìˆ˜ìˆ˜ë£Œ ë“± í¬í•¨)")
        
        if "messages" not in st.session_state: st.session_state.messages = []
        for message in st.session_state.messages:
            with st.chat_message(message["role"]): st.markdown(message["content"])

        user_question = st.chat_input("ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”...")
        if user_question:
            st.session_state.messages.append({"role": "user", "content": user_question})
            with st.chat_message("user"): st.markdown(user_question)
            if g_model:
                with st.spinner("AIê°€ ë‹µë³€ì„ ìƒì„± ì¤‘ì…ë‹ˆë‹¤..."):
                    with st.chat_message("assistant"):
                        answer = get_ai_answer(g_model, df, user_question)
                        st.markdown(answer)
                        st.session_state.messages.append({"role": "assistant", "content": answer})
            else: st.warning("AI ëª¨ë¸ì´ ì—°ê²°ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
